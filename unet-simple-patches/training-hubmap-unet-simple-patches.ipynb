{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height:200px;width:100%;margin: 0;\">\n",
    "    <img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/34547/logos/header.png?t=2022-02-15-22-37-27\" style=\"width:100%;\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"credits\"><center>Credits</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the reverse engineering of the [hengck23 discussion](https://www.kaggle.com/code/hengck23/lb-0-75-variable-size-swin-transformer-v1-and-v2).<br>\n",
    "Please upvote both discussion/notebooks if you are planning to use Swin Transformers or any part of the code.\n",
    "\n",
    "**hengck23 owner Disclaimer**\n",
    "\n",
    "[1] the code is taken from a larger project and is by no means complete. It will has missing import modules, etc. But these are trival functions that you can ignore or fill in yourself.\n",
    "\n",
    "[2] you are free to use, modify the code for your own notebook or submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"imports\"><center>Imports</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.cuda.amp as amp\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import RandomSampler \n",
    "from torch.utils.data import SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional import dice_score\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "is_amp = True\n",
    "import logging\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import numpy as np\n",
    "from itertools import repeat\n",
    "import collections.abc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"paths\"><center>Paths</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip archive\\(2\\).zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_dir = '.'\n",
    "root_dir = '.'\n",
    "\n",
    "TRAIN = '../data/data_256/train/'\n",
    "MASKS = '../data/data_256/masks/'\n",
    "LABELS = '../data/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = cv.imread('./../data/data_256/masks/10044_0001.png', cv.IMREAD_GRAYSCALE)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, dtype('uint8'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.min(), data.max(), data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"additionals\"><center>Additionals</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "def image_to_tensor(image, mode='bgr'): #image mode\n",
    "    if mode=='bgr':\n",
    "        image = image[:,:,::-1]\n",
    "    x = image\n",
    "    x = x.transpose(2,0,1)\n",
    "    x = np.ascontiguousarray(x)\n",
    "    x = torch.tensor(x, dtype=torch.float)\n",
    "    return x\n",
    "\n",
    "\n",
    "def mask_to_tensor(mask):\n",
    "    x = mask\n",
    "    x = torch.tensor(x, dtype=torch.float)\n",
    "    return x\n",
    "\n",
    "\n",
    "tensor_list = ['mask', 'image', 'organ']\n",
    "\n",
    "def null_collate(batch):\n",
    "    d = {}\n",
    "    key = batch[0].keys()\n",
    "    for k in key:\n",
    "        v = [b[k] for b in batch]\n",
    "        if k in tensor_list:\n",
    "            v = torch.stack(v)\n",
    "        d[k] = v\n",
    "\n",
    "    d['mask'] = d['mask'].unsqueeze(1)\n",
    "    d['organ'] = d['organ'].reshape(-1)\n",
    "    return d\n",
    "\n",
    "\n",
    "def _ntuple(n):\n",
    "    def parse(x):\n",
    "        if isinstance(x, collections.abc.Iterable):\n",
    "            return x\n",
    "        return tuple(repeat(x, n))\n",
    "    return parse\n",
    "\n",
    "\n",
    "to_2tuple = _ntuple(2)\n",
    "\n",
    "\n",
    "def _no_grad_trunc_normal_(tensor, mean, std, a, b):\n",
    "    # Cut & paste from PyTorch official master until it's in a few official releases - RW\n",
    "    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n",
    "    def norm_cdf(x):\n",
    "        # Computes standard normal cumulative distribution function\n",
    "        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n",
    "\n",
    "    if (mean < a - 2 * std) or (mean > b + 2 * std):\n",
    "        warnings.warn(\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"\n",
    "                      \"The distribution of values may be incorrect.\",\n",
    "                      stacklevel=2)\n",
    "\n",
    "        \n",
    "def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n",
    "    return _no_grad_trunc_normal_(tensor, mean, std, a, b)\n",
    "\n",
    "\n",
    "def drop_path(x, drop_prob: float = 0., training: bool = False, scale_by_keep: bool = True):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n",
    "    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n",
    "    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n",
    "    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n",
    "    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n",
    "    'survival rate' as the argument.\n",
    "    \"\"\"\n",
    "    if drop_prob == 0. or not training:\n",
    "        return x\n",
    "    keep_prob = 1 - drop_prob\n",
    "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
    "    random_tensor = x.new_empty(shape).bernoulli_(keep_prob)\n",
    "    if keep_prob > 0.0 and scale_by_keep:\n",
    "        random_tensor.div_(keep_prob)\n",
    "    return x * random_tensor\n",
    "\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
    "    \"\"\"\n",
    "    def __init__(self, drop_prob: float = 0., scale_by_keep: bool = True):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.scale_by_keep = scale_by_keep\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training, self.scale_by_keep)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f'drop_prob={round(self.drop_prob,3):0.3f}'\n",
    "    \n",
    "    \n",
    "class RGB(nn.Module):\n",
    "    IMAGE_RGB_MEAN = [0.485, 0.456, 0.406] #[0.5, 0.5, 0.5]\n",
    "    IMAGE_RGB_STD  = [0.229, 0.224, 0.225] #[0.5, 0.5, 0.5]\n",
    "\n",
    "    def __init__(self,):\n",
    "        super(RGB, self).__init__()\n",
    "        self.register_buffer('mean', torch.zeros(1,3,1,1))\n",
    "        self.register_buffer('std', torch.ones(1,3,1,1))\n",
    "        self.mean.data = torch.FloatTensor(self.IMAGE_RGB_MEAN).view(self.mean.shape)\n",
    "        self.std.data = torch.FloatTensor(self.IMAGE_RGB_STD).view(self.std.shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = (x-self.mean)/self.std\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def message(mode='print'):\n",
    "    asterisk = ' '\n",
    "    if mode==('print'):\n",
    "        loss = batch_loss\n",
    "    if mode==('log'):\n",
    "        loss = train_loss\n",
    "        if (iteration % iter_save == 0): asterisk = '*'\n",
    "\n",
    "    text = \\\n",
    "        ('%0.2e   %08d%s %6.2f | '%(rate, iteration, asterisk, epoch,)).replace('e-0','e-').replace('e+0','e+') + \\\n",
    "        '%4.3f  %4.3f  %4.4f  %4.3f   | '%(*valid_loss,) + \\\n",
    "        '%4.3f  %4.3f   | '%(*loss,) + \\\n",
    "        '%s' % ((time.time() - start_timer))\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"randoms\"><center>Random choice</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_augment5(image, mask, organ):\n",
    "    #image, mask  = do_crop(image, mask, image_size, xy=(None,None))\n",
    "    return image, mask\n",
    "\n",
    "def train_augment5b(image, mask, organ):\n",
    "    image, mask = do_random_flip(image, mask)\n",
    "    image, mask = do_random_rot90(image, mask)\n",
    "\n",
    "    for fn in np.random.choice([\n",
    "        lambda image, mask: (image, mask),\n",
    "        lambda image, mask: do_random_noise(image, mask, mag=0.1),\n",
    "        lambda image, mask: do_random_contast(image, mask, mag=0.40),\n",
    "        lambda image, mask: do_random_hsv(image, mask, mag=[0.40, 0.40, 0])\n",
    "    ], 2): image, mask = fn(image, mask)\n",
    "\n",
    "    for fn in np.random.choice([\n",
    "        lambda image, mask: (image, mask),\n",
    "        lambda image, mask: do_random_rotate_scale(image, mask, angle=45, scale=[0.50, 2.0]),\n",
    "    ], 1): image, mask = fn(image, mask)\n",
    "\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"augmentations\"><center>Augmentations</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "def do_random_flip(image, mask):\n",
    "    if np.random.rand()>0.5:\n",
    "        image = cv2.flip(image,0)\n",
    "        mask = cv2.flip(mask,0)\n",
    "    if np.random.rand()>0.5:\n",
    "        image = cv2.flip(image,1)\n",
    "        mask = cv2.flip(mask,1)\n",
    "    if np.random.rand()>0.5:\n",
    "        image = image.transpose(1,0,2)\n",
    "        mask = mask.transpose(1,0)\n",
    "    \n",
    "    image = np.ascontiguousarray(image)\n",
    "    mask = np.ascontiguousarray(mask)\n",
    "    return image, mask\n",
    "\n",
    "def do_random_rot90(image, mask):\n",
    "    r = np.random.choice([\n",
    "        0,\n",
    "        cv2.ROTATE_90_CLOCKWISE,\n",
    "        cv2.ROTATE_90_COUNTERCLOCKWISE,\n",
    "        cv2.ROTATE_180,\n",
    "    ])\n",
    "    if r==0:\n",
    "        return image, mask\n",
    "    else:\n",
    "        image = cv2.rotate(image, r)\n",
    "        mask = cv2.rotate(mask, r)\n",
    "        return image, mask\n",
    "    \n",
    "def do_random_contast(image, mask, mag=0.3):\n",
    "    alpha = 1 + random.uniform(-1,1)*mag\n",
    "    image = image * alpha\n",
    "    image = np.clip(image,0,1)\n",
    "    return image, mask\n",
    "\n",
    "def do_random_hsv(image, mask, mag=[0.15,0.25,0.25]):\n",
    "    image = (image*255).astype(np.uint8)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    h = hsv[:, :, 0].astype(np.float32)  # hue\n",
    "    s = hsv[:, :, 1].astype(np.float32)  # saturation\n",
    "    v = hsv[:, :, 2].astype(np.float32)  # value\n",
    "    h = (h*(1 + random.uniform(-1,1)*mag[0]))%180\n",
    "    s =  s*(1 + random.uniform(-1,1)*mag[1])\n",
    "    v =  v*(1 + random.uniform(-1,1)*mag[2])\n",
    "\n",
    "    hsv[:, :, 0] = np.clip(h,0,180).astype(np.uint8)\n",
    "    hsv[:, :, 1] = np.clip(s,0,255).astype(np.uint8)\n",
    "    hsv[:, :, 2] = np.clip(v,0,255).astype(np.uint8)\n",
    "    image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    image = image.astype(np.float32)/255\n",
    "    return image, mask\n",
    "\n",
    "def do_random_noise(image, mask, mag=0.1):\n",
    "    height, width = image.shape[:2]\n",
    "    noise = np.random.uniform(-1,1, (height, width,1))*mag\n",
    "    image = image + noise\n",
    "    image = np.clip(image,0,1)\n",
    "    return image, mask\n",
    "\n",
    "def do_random_rotate_scale(image, mask, angle=30, scale=[0.8,1.2] ):\n",
    "    angle = np.random.uniform(-angle, angle)\n",
    "    scale = np.random.uniform(*scale) if scale is not None else 1\n",
    "    \n",
    "    height, width = image.shape[:2]\n",
    "    center = (height // 2, width // 2)\n",
    "    \n",
    "    transform = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    image = cv2.warpAffine( image, transform, (width, height), flags=cv2.INTER_LINEAR,\n",
    "                            borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))\n",
    "    mask  = cv2.warpAffine( mask, transform, (width, height), flags=cv2.INTER_LINEAR,\n",
    "                            borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"dataset\"><center>Dataset</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 768\n",
    "\n",
    "class HubmapDataset(Dataset):\n",
    "    def __init__(self, df, augment=None):\n",
    "\n",
    "        self.df = df\n",
    "        self.augment = augment\n",
    "        self.length = len(self.df)\n",
    "        ids = pd.read_csv(LABELS).id.astype(str).values\n",
    "        self.fnames = [fname for fname in os.listdir(TRAIN)]# if fname.split('_')[0] in ids]\n",
    "        self.organ_to_label = {'kidney' : 0,\n",
    "                               'prostate' : 1,\n",
    "                               'largeintestine' : 2,\n",
    "                               'spleen' : 3,\n",
    "                               'lung' : 4}\n",
    "\n",
    "    def __str__(self):\n",
    "        string = ''\n",
    "        string += '\\tlen = %d\\n' % len(self)\n",
    "\n",
    "        d = self.df.organ.value_counts().to_dict()\n",
    "        for k in ['kidney', 'prostate', 'largeintestine', 'spleen', 'lung']:\n",
    "            string +=  '%24s %3d (%0.3f) \\n'%(k,d.get(k,0),d.get(k,0)/len(self.df))\n",
    "        return string\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fname = self.fnames[index]\n",
    "        d = self.df.iloc[index]\n",
    "        organ = self.organ_to_label[d.organ]\n",
    "\n",
    "        image = cv2.cvtColor(cv2.imread(os.path.join(TRAIN,fname)), cv2.COLOR_BGR2RGB)\n",
    "#         mask = cv2.imread(os.path.join(MASKS,fname),cv2.IMREAD_GRAYSCALE)\n",
    "        mask = np.load(os.path.join(MASKS,fname.replace('.png', '.npy')),cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        \n",
    "        image = image.astype(np.float32)/255\n",
    "        mask  = mask.astype(np.float32) #/255\n",
    "\n",
    "#         s = d.pixel_size/0.4 * (image_size/3000)\n",
    "        image = cv2.resize(image,dsize=(image_size,image_size),interpolation=cv2.INTER_LINEAR)\n",
    "        mask  = cv2.resize(mask, dsize=(image_size,image_size),interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        if self.augment is not None:\n",
    "            image, mask = self.augment(image, mask, organ)\n",
    "\n",
    "\n",
    "        r ={}\n",
    "        r['index']= index\n",
    "        r['id'] = fname\n",
    "        r['organ'] = torch.tensor([organ], dtype=torch.long)\n",
    "        r['image'] = image_to_tensor(image)\n",
    "        r['mask' ] = mask_to_tensor(mask>0.5)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"patching\"><center>NETWORK</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "from swintransformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "def run_check_net():\n",
    "    batch_size = 2\n",
    "    image_size = 512\n",
    "\n",
    "    #---\n",
    "    batch = {\n",
    "        'image' : torch.from_numpy( np.random.uniform(-1,1,(batch_size,3,image_size,image_size)) ).float(),\n",
    "        'mask'  : torch.from_numpy( np.random.choice(2,(batch_size,1,image_size,image_size)) ).float(),\n",
    "        'organ' : torch.from_numpy( np.random.choice(5,(batch_size)) ).long(),\n",
    "    }\n",
    "    batch = {k:v.cuda() for k,v in batch.items()}\n",
    "\n",
    "    net = Net().cuda()\n",
    "    net.load_pretrain()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            output = net(batch)\n",
    "\n",
    "    print('batch')\n",
    "    for k,v in batch.items():\n",
    "        print('%32s :'%k, v.shape)\n",
    "\n",
    "    print('output')\n",
    "    for k,v in output.items():\n",
    "        if 'loss' not in k:\n",
    "            print('%32s :'%k, v.shape)\n",
    "    for k,v in output.items():\n",
    "        if 'loss' in k:\n",
    "            print('%32s :'%k, v.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = dict(\n",
    "\n",
    "        #configs/_base_/models/upernet_swin.py\n",
    "        basic = dict(\n",
    "            swin=dict(\n",
    "                embed_dim=96,\n",
    "                depths=[2, 2, 6, 2],\n",
    "                num_heads=[3, 6, 12, 24],\n",
    "                window_size=7,\n",
    "                mlp_ratio=4.,\n",
    "                qkv_bias=True,\n",
    "                qk_scale=None,\n",
    "                drop_rate=0.,\n",
    "                attn_drop_rate=0.,\n",
    "                drop_path_rate=0.3,\n",
    "                ape=False,\n",
    "                patch_norm=True,\n",
    "                out_indices=(0, 1, 2, 3),\n",
    "                use_checkpoint=False\n",
    "            ),\n",
    "\n",
    "        ),\n",
    "\n",
    "        #configs/swin/upernet_swin_tiny_patch4_window7_512x512_160k_ade20k.py\n",
    "        swin_tiny_patch4_window7_224=dict(\n",
    "            checkpoint = pretrain_dir+'/swin_tiny_patch4_window7_224_22k.pth',\n",
    "\n",
    "            swin = dict(\n",
    "                embed_dim=96,\n",
    "                depths=[2, 2, 6, 2],\n",
    "                num_heads=[3, 6, 12, 24],\n",
    "                window_size=7,\n",
    "                ape=False,\n",
    "                drop_path_rate=0.3,\n",
    "                patch_norm=True,\n",
    "                use_checkpoint=False,\n",
    "            ),\n",
    "            upernet=dict(\n",
    "                in_channels=[96, 192, 384, 768],\n",
    "            ),\n",
    "        ),\n",
    "\n",
    "        #/configs/swin/upernet_swin_small_patch4_window7_512x512_160k_ade20k.py\n",
    "        swin_small_patch4_window7_224_22k=dict(\n",
    "            checkpoint = pretrain_dir+'/swin_small_patch4_window7_224_22k.pth',\n",
    "\n",
    "            swin = dict(\n",
    "                embed_dim=96,\n",
    "                depths=[2, 2, 18, 2],\n",
    "                num_heads=[3, 6, 12, 24],\n",
    "                window_size=7,\n",
    "                ape=False,\n",
    "                drop_path_rate=0.3,\n",
    "                patch_norm=True,\n",
    "                use_checkpoint=False\n",
    "            ),\n",
    "            upernet=dict(\n",
    "                in_channels=[96, 192, 384, 768],\n",
    "            ),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"folds\"><center>Folds</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fold(fold=0):\n",
    "    df = pd.read_csv(root_dir + '/../data/train.csv')\n",
    "\n",
    "    num_fold = 5\n",
    "    skf = KFold(n_splits=num_fold, shuffle=True,random_state=42)\n",
    "\n",
    "    df.loc[:,'fold']=-1\n",
    "    for f,(t_idx, v_idx) in enumerate(skf.split(X=df['id'], y=df['organ'])):\n",
    "        df.iloc[v_idx,-1]=f\n",
    "\n",
    "    #check\n",
    "    if 0:\n",
    "        for f in range(num_fold):\n",
    "            train_df=df[df.fold!=f].reset_index(drop=True)\n",
    "            valid_df=df[df.fold==f].reset_index(drop=True)\n",
    "\n",
    "            print('fold %d'%f)\n",
    "            t = train_df.organ.value_counts().to_dict()\n",
    "            v = valid_df.organ.value_counts().to_dict()\n",
    "            for k in ['kidney', 'prostate', 'largeintestine', 'spleen', 'lung']:\n",
    "                print('%32s %3d (%0.3f)  %3d (%0.3f)'%(k,t.get(k,0),t.get(k,0)/len(train_df),v.get(k,0),v.get(k,0)/len(valid_df)))\n",
    "\n",
    "            print('')\n",
    "            zz=0\n",
    "\n",
    "    train_df=df[df.fold!=fold].reset_index(drop=True)\n",
    "    valid_df=df[df.fold==fold].reset_index(drop=True)\n",
    "    return train_df,valid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"dice_score\"><center>Competition Metric</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dice_score(probability, mask):\n",
    "    N = len(probability)\n",
    "    p = probability.reshape(N,-1)\n",
    "    t = mask.reshape(N,-1)\n",
    "\n",
    "    p = p>0.5\n",
    "    t = t>0.5\n",
    "    uion = p.sum(-1) + t.sum(-1)\n",
    "    overlap = (p*t).sum(-1)\n",
    "    dice = 2*overlap/(uion+0.0001)\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"validation\"><center>Validation</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net, valid_loader):\n",
    "\n",
    "    valid_num = 0\n",
    "    valid_probability = []\n",
    "    valid_mask = []\n",
    "    valid_loss = 0\n",
    "\n",
    "    net = net.eval()\n",
    "    start_timer = time.time()\n",
    "    for t, batch in enumerate(valid_loader):\n",
    "\n",
    "        net.output_type = ['loss', 'inference']\n",
    "        with torch.no_grad():\n",
    "            with amp.autocast(enabled = is_amp):\n",
    "\n",
    "                batch_size = len(batch['index'])\n",
    "                batch['image'] = batch['image'].cuda()\n",
    "                batch['mask' ] = batch['mask' ].cuda()\n",
    "                batch['organ'] = batch['organ'].cuda()\n",
    "\n",
    "                output = net(batch)\n",
    "                loss0  = output['bce_loss'].mean()\n",
    "\n",
    "        valid_probability.append(output['probability'].data.cpu().numpy())\n",
    "        valid_mask.append(batch['mask'].data.cpu().numpy())\n",
    "        valid_num += batch_size\n",
    "        valid_loss += batch_size*loss0.item()\n",
    "\n",
    "        #debug\n",
    "        if 0 :\n",
    "            pass\n",
    "            organ = batch['organ'].data.cpu().numpy()\n",
    "            image = batch['image']\n",
    "            mask  = batch['mask']\n",
    "            probability  = output['probability']\n",
    "\n",
    "            for b in range(batch_size):\n",
    "                m = tensor_to_image(image[b])\n",
    "                t = tensor_to_mask(mask[b,0])\n",
    "                p = tensor_to_mask(probability[b,0])\n",
    "                overlay = result_to_overlay(m, t, p )\n",
    "\n",
    "                text = label_to_organ[organ[b]]\n",
    "                draw_shadow_text(overlay,text,(5,15),0.7,(1,1,1),1)\n",
    "\n",
    "                image_show_norm('overlay',overlay,min=0,max=1,resize=1)\n",
    "                cv2.waitKey(0)\n",
    "\n",
    "        print('\\r %8d / %d  %s'%(valid_num, len(valid_loader.dataset),(time.time() - start_timer)),end='',flush=True)\n",
    "\n",
    "    assert(valid_num == len(valid_loader.dataset))\n",
    "\n",
    "    probability = np.concatenate(valid_probability)\n",
    "    mask = np.concatenate(valid_mask)\n",
    "\n",
    "    loss = valid_loss/valid_num\n",
    "\n",
    "    dice = compute_dice_score(probability, mask)\n",
    "    dice = dice.mean()\n",
    "    \n",
    "    return [dice, loss,  0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"init\"><center>Initialization</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learning_rate(optimizer):\n",
    "    return optimizer.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir fold_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./swin_tiny_patch4_window7_224_22k.pth ...\n",
      "_IncompatibleKeys(missing_keys=['out_norm.0.weight', 'out_norm.0.bias', 'out_norm.1.weight', 'out_norm.1.bias', 'out_norm.2.weight', 'out_norm.2.bias', 'out_norm.3.weight', 'out_norm.3.bias'], unexpected_keys=['norm.weight', 'norm.bias', 'head.weight', 'head.bias', 'layers.0.blocks.1.attn_mask', 'layers.1.blocks.1.attn_mask', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.5.attn_mask'])\n"
     ]
    }
   ],
   "source": [
    "fold = FOLD\n",
    "\n",
    "out_dir = root_dir + '/fold-%d' % (fold)\n",
    "initial_checkpoint = None\n",
    "\n",
    "start_lr   = 5e-5 #0.0001\n",
    "batch_size = 8 #32 #32\n",
    "\n",
    "\n",
    "## setup  ----------------------------------------\n",
    "for f in ['checkpoint','train','valid','backup'] : os.makedirs(out_dir +'/'+f, exist_ok=True)\n",
    "\n",
    "    \n",
    "log = open(out_dir+'/log.train.txt',mode='a')\n",
    "log.write('\\n--- [START %s] %s\\n\\n' % ('Swin', '-' * 64))\n",
    "log.write('\\n')\n",
    "\n",
    "\n",
    "## dataset ----------------------------------------\n",
    "log.write('** dataset setting **\\n')\n",
    "\n",
    "train_df, valid_df = make_fold(fold)\n",
    "\n",
    "train_dataset = HubmapDataset(train_df, train_augment5b)\n",
    "valid_dataset = HubmapDataset(valid_df, valid_augment5)\n",
    "\n",
    "train_loader  = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler = RandomSampler(train_dataset),\n",
    "    batch_size  = batch_size,\n",
    "    drop_last   = True,\n",
    "    num_workers = 8,\n",
    "    pin_memory  = False,\n",
    "    worker_init_fn = lambda id: np.random.seed(torch.initial_seed() // 2 ** 32 + id),\n",
    "    collate_fn = null_collate,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    sampler = SequentialSampler(valid_dataset),\n",
    "    batch_size  = 8,\n",
    "    drop_last   = False,\n",
    "    num_workers = 4,\n",
    "    pin_memory  = False,\n",
    "    collate_fn = null_collate,\n",
    ")\n",
    "\n",
    "\n",
    "log.write('fold = %s\\n'%str(fold))\n",
    "log.write('train_dataset : \\n%s\\n'%(train_dataset))\n",
    "log.write('valid_dataset : \\n%s\\n'%(valid_dataset))\n",
    "log.write('\\n')\n",
    "\n",
    "\n",
    "## net ----------------------------------------\n",
    "log.write('** net setting **\\n')\n",
    "\n",
    "scaler = amp.GradScaler(enabled = is_amp)\n",
    "net = Net(cfg).cuda()\n",
    "\n",
    "if initial_checkpoint is not None:\n",
    "    f = torch.load(initial_checkpoint, map_location=lambda storage, loc: storage)\n",
    "    start_iteration = f['iteration']\n",
    "    start_epoch = f['epoch']\n",
    "    state_dict  = f['state_dict']\n",
    "    net.load_state_dict(state_dict,strict=False)  #True\n",
    "else:\n",
    "    start_iteration = 0\n",
    "    start_epoch = 0\n",
    "    net.load_pretrain()\n",
    "\n",
    "\n",
    "log.write('\\tinitial_checkpoint = %s\\n' % initial_checkpoint)\n",
    "log.write('\\n')\n",
    "\n",
    "\n",
    "## optimiser ----------------------------------\n",
    "if 0: ##freeze\n",
    "    for p in net.stem.parameters():   p.requires_grad = False\n",
    "    pass\n",
    "\n",
    "def freeze_bn(net):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            m.eval()\n",
    "            m.weight.requires_grad = False\n",
    "            m.bias.requires_grad = False\n",
    "            \n",
    "#freeze_bn(net)\n",
    "\n",
    "#-----------------------------------------------\n",
    "\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, net.parameters()),lr=start_lr)\n",
    "\n",
    "log.write('optimizer\\n  %s\\n'%(optimizer))\n",
    "log.write('\\n')\n",
    "\n",
    "num_iteration = 1000*len(train_loader)\n",
    "iter_log   = len(train_loader)*3 #479\n",
    "iter_valid = iter_log\n",
    "iter_save  = iter_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>organ</th>\n",
       "      <th>data_source</th>\n",
       "      <th>img_height</th>\n",
       "      <th>img_width</th>\n",
       "      <th>pixel_size</th>\n",
       "      <th>tissue_thickness</th>\n",
       "      <th>rle</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10274</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>715707 2 718705 8 721703 11 724701 18 727692 3...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10392</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1228631 20 1231629 24 1234624 40 1237623 47 12...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10488</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3446519 15 3449517 17 3452514 20 3455510 24 34...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10611</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>730193 18 733191 25 736191 25 739152 65 742149...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10651</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1240229 12 1243227 15 1246223 26 1249221 29 12...</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10666</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2698231 7 2701231 7 2704226 16 2707221 25 2710...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10892</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>523786 3 526784 8 529782 8 532778 9 535642 25 ...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10912</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1147323 50 1150316 59 1153309 68 1156303 76 11...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10971</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1507862 60 1510857 69 1513853 77 1516848 86 15...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11064</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2210040 68 2213039 70 2216036 74 2219032 79 22...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11448</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3450282 28 3453278 33 3456272 53 3459271 56 34...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11497</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>940436 51 943430 65 946427 76 949423 89 952417...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1157</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4883571 15 4886565 32 4889561 41 4892559 49 48...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11629</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4143554 1 4146554 2 4149554 3 4152555 3 415555...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11645</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>2867</td>\n",
       "      <td>2867</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1971766 32 1974633 34 1977499 36 1980366 37 19...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11662</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>673655 29 676649 41 679645 47 682638 59 685636...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1168</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>652348 27 655344 35 658310 79 661305 93 664303...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1184</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1916384 12 1919383 15 1922378 26 1925376 29 19...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11890</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1297230 32 1300222 46 1303215 60 1306213 63 13...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12026</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>568261 32 571258 36 574256 38 577245 61 580243...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>12174</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>592530 6 595511 36 598506 43 601493 63 604487 ...</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1229</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>2654</td>\n",
       "      <td>2654</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>229957 31 232610 33 235217 84 237869 87 240521...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12452</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4648688 22 4651675 37 4654675 39 4657670 48 46...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12466</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>920222 4 923221 6 926221 6 929220 10 932218 14...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12476</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2783561 23 2786559 26 2789558 28 2792556 31 27...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12483</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3358269 61 3361268 64 3364267 67 3367247 89 33...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12827</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3210652 9 3213650 16 3216647 21 3219645 24 322...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13034</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>850253 18 853250 24 856245 32 859237 46 862233...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13189</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1844328 7 1847327 10 1850270 27 1850326 13 185...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>13483</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1291312 12 1294311 14 1297252 79 1300251 81 13...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>7902</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2490568 9 2493561 23 2496559 26 2499558 28 250...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>7970</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1964081 19 1967076 25 1970075 27 1973073 34 19...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>8151</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2057037 10 2060034 13 2063031 17 2066027 21 20...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>8222</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>165901 31 168900 33 171891 44 174890 47 177888...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>8227</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>529710 25 532708 28 535700 40 538699 43 541698...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>8231</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3707337 1 3710337 2 3713336 4 3716336 6 371933...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>8343</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2170394 3 2173394 6 2176394 7 2179395 7 218239...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>8388</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2989254 26 2992254 28 2995251 35 2998246 45 30...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>8402</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>679462 5 682457 13 685448 25 685504 27 688447 ...</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>8450</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>736706 12 739698 33 742691 52 745689 67 748686...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>8502</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2308023 17 2311014 30 2314004 49 2317000 59 23...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>8638</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3312310 10 3315310 11 3318301 25 3321299 27 33...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>8752</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>793679 20 796675 32 799670 74 802662 95 805654...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>8842</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1430055 19 1430115 36 1433053 21 1433114 38 14...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>8876</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3102247 12 3105246 14 3108246 19 3111245 20 31...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>8894</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>934450 1 937448 3 940447 3 943445 5 946444 5 9...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>9231</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1048080 26 1051079 28 1054078 30 1057071 39 10...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>928</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1980656 1 1980673 27 1981666 48 1983655 1 1983...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>9358</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4173254 1 4176253 2 4179251 3 4182250 4 418524...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>9387</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1996630 8 1999626 14 2002624 16 2005622 19 200...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>9407</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2184669 23 2187667 27 2190665 31 2193661 37 21...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>9437</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>841572 20 844566 38 847564 45 850563 50 853555...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>9445</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>5515207 20 5518204 29 5521202 35 5524202 36 55...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>9453</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3270895 59 3273894 62 3276888 69 3279887 71 32...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>9470</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3969980 35 3970027 28 3972971 88 3975966 97 39...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>9517</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1611763 11 1614753 29 1617750 35 1620746 43 16...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>9769</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3070</td>\n",
       "      <td>3070</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4030400 28 4033466 34 4036526 48 4039594 54 40...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>9777</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>538473 13 541468 22 544463 30 547461 35 550459...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>9791</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>334733 33 337729 43 340729 43 343725 51 346723...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>9904</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1009165 7 1012149 28 1015140 38 1018127 51 102...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id           organ data_source  img_height  img_width  pixel_size  \\\n",
       "0    10274        prostate         HPA        3000       3000         0.4   \n",
       "1    10392          spleen         HPA        3000       3000         0.4   \n",
       "2    10488            lung         HPA        3000       3000         0.4   \n",
       "3    10611          kidney         HPA        3000       3000         0.4   \n",
       "4    10651  largeintestine         HPA        3000       3000         0.4   \n",
       "5    10666        prostate         HPA        3000       3000         0.4   \n",
       "6    10892  largeintestine         HPA        3000       3000         0.4   \n",
       "7    10912        prostate         HPA        3000       3000         0.4   \n",
       "8    10971        prostate         HPA        3000       3000         0.4   \n",
       "9    11064            lung         HPA        3000       3000         0.4   \n",
       "10   11448          spleen         HPA        3000       3000         0.4   \n",
       "11   11497          kidney         HPA        3000       3000         0.4   \n",
       "12    1157          kidney         HPA        3000       3000         0.4   \n",
       "13   11629            lung         HPA        3000       3000         0.4   \n",
       "14   11645          spleen         HPA        2867       2867         0.4   \n",
       "15   11662  largeintestine         HPA        3000       3000         0.4   \n",
       "16    1168  largeintestine         HPA        3000       3000         0.4   \n",
       "17    1184        prostate         HPA        3000       3000         0.4   \n",
       "18   11890  largeintestine         HPA        3000       3000         0.4   \n",
       "19   12026          spleen         HPA        3000       3000         0.4   \n",
       "20   12174  largeintestine         HPA        3000       3000         0.4   \n",
       "21    1229        prostate         HPA        2654       2654         0.4   \n",
       "22   12452            lung         HPA        3000       3000         0.4   \n",
       "23   12466          spleen         HPA        3000       3000         0.4   \n",
       "24   12476            lung         HPA        3000       3000         0.4   \n",
       "25   12483          spleen         HPA        3000       3000         0.4   \n",
       "26   12827            lung         HPA        3000       3000         0.4   \n",
       "27   13034          kidney         HPA        3000       3000         0.4   \n",
       "28   13189            lung         HPA        3000       3000         0.4   \n",
       "29   13483        prostate         HPA        3000       3000         0.4   \n",
       "..     ...             ...         ...         ...        ...         ...   \n",
       "251   7902        prostate         HPA        3000       3000         0.4   \n",
       "252   7970          kidney         HPA        3000       3000         0.4   \n",
       "253   8151            lung         HPA        3000       3000         0.4   \n",
       "254   8222  largeintestine         HPA        3000       3000         0.4   \n",
       "255   8227        prostate         HPA        3000       3000         0.4   \n",
       "256   8231            lung         HPA        3000       3000         0.4   \n",
       "257   8343            lung         HPA        3000       3000         0.4   \n",
       "258   8388        prostate         HPA        3000       3000         0.4   \n",
       "259   8402  largeintestine         HPA        3000       3000         0.4   \n",
       "260   8450  largeintestine         HPA        3000       3000         0.4   \n",
       "261   8502          kidney         HPA        3000       3000         0.4   \n",
       "262   8638        prostate         HPA        3000       3000         0.4   \n",
       "263   8752  largeintestine         HPA        3000       3000         0.4   \n",
       "264   8842        prostate         HPA        3000       3000         0.4   \n",
       "265   8876          spleen         HPA        3000       3000         0.4   \n",
       "266   8894          spleen         HPA        3000       3000         0.4   \n",
       "267   9231        prostate         HPA        3000       3000         0.4   \n",
       "268    928        prostate         HPA        3000       3000         0.4   \n",
       "269   9358        prostate         HPA        3000       3000         0.4   \n",
       "270   9387            lung         HPA        3000       3000         0.4   \n",
       "271   9407          spleen         HPA        3000       3000         0.4   \n",
       "272   9437          kidney         HPA        3000       3000         0.4   \n",
       "273   9445          kidney         HPA        3000       3000         0.4   \n",
       "274   9453          spleen         HPA        3000       3000         0.4   \n",
       "275   9470          kidney         HPA        3000       3000         0.4   \n",
       "276   9517          kidney         HPA        3000       3000         0.4   \n",
       "277   9769          kidney         HPA        3070       3070         0.4   \n",
       "278   9777  largeintestine         HPA        3000       3000         0.4   \n",
       "279   9791          kidney         HPA        3000       3000         0.4   \n",
       "280   9904  largeintestine         HPA        3000       3000         0.4   \n",
       "\n",
       "     tissue_thickness                                                rle  \\\n",
       "0                   4  715707 2 718705 8 721703 11 724701 18 727692 3...   \n",
       "1                   4  1228631 20 1231629 24 1234624 40 1237623 47 12...   \n",
       "2                   4  3446519 15 3449517 17 3452514 20 3455510 24 34...   \n",
       "3                   4  730193 18 733191 25 736191 25 739152 65 742149...   \n",
       "4                   4  1240229 12 1243227 15 1246223 26 1249221 29 12...   \n",
       "5                   4  2698231 7 2701231 7 2704226 16 2707221 25 2710...   \n",
       "6                   4  523786 3 526784 8 529782 8 532778 9 535642 25 ...   \n",
       "7                   4  1147323 50 1150316 59 1153309 68 1156303 76 11...   \n",
       "8                   4  1507862 60 1510857 69 1513853 77 1516848 86 15...   \n",
       "9                   4  2210040 68 2213039 70 2216036 74 2219032 79 22...   \n",
       "10                  4  3450282 28 3453278 33 3456272 53 3459271 56 34...   \n",
       "11                  4  940436 51 943430 65 946427 76 949423 89 952417...   \n",
       "12                  4  4883571 15 4886565 32 4889561 41 4892559 49 48...   \n",
       "13                  4  4143554 1 4146554 2 4149554 3 4152555 3 415555...   \n",
       "14                  4  1971766 32 1974633 34 1977499 36 1980366 37 19...   \n",
       "15                  4  673655 29 676649 41 679645 47 682638 59 685636...   \n",
       "16                  4  652348 27 655344 35 658310 79 661305 93 664303...   \n",
       "17                  4  1916384 12 1919383 15 1922378 26 1925376 29 19...   \n",
       "18                  4  1297230 32 1300222 46 1303215 60 1306213 63 13...   \n",
       "19                  4  568261 32 571258 36 574256 38 577245 61 580243...   \n",
       "20                  4  592530 6 595511 36 598506 43 601493 63 604487 ...   \n",
       "21                  4  229957 31 232610 33 235217 84 237869 87 240521...   \n",
       "22                  4  4648688 22 4651675 37 4654675 39 4657670 48 46...   \n",
       "23                  4  920222 4 923221 6 926221 6 929220 10 932218 14...   \n",
       "24                  4  2783561 23 2786559 26 2789558 28 2792556 31 27...   \n",
       "25                  4  3358269 61 3361268 64 3364267 67 3367247 89 33...   \n",
       "26                  4  3210652 9 3213650 16 3216647 21 3219645 24 322...   \n",
       "27                  4  850253 18 853250 24 856245 32 859237 46 862233...   \n",
       "28                  4  1844328 7 1847327 10 1850270 27 1850326 13 185...   \n",
       "29                  4  1291312 12 1294311 14 1297252 79 1300251 81 13...   \n",
       "..                ...                                                ...   \n",
       "251                 4  2490568 9 2493561 23 2496559 26 2499558 28 250...   \n",
       "252                 4  1964081 19 1967076 25 1970075 27 1973073 34 19...   \n",
       "253                 4  2057037 10 2060034 13 2063031 17 2066027 21 20...   \n",
       "254                 4  165901 31 168900 33 171891 44 174890 47 177888...   \n",
       "255                 4  529710 25 532708 28 535700 40 538699 43 541698...   \n",
       "256                 4  3707337 1 3710337 2 3713336 4 3716336 6 371933...   \n",
       "257                 4  2170394 3 2173394 6 2176394 7 2179395 7 218239...   \n",
       "258                 4  2989254 26 2992254 28 2995251 35 2998246 45 30...   \n",
       "259                 4  679462 5 682457 13 685448 25 685504 27 688447 ...   \n",
       "260                 4  736706 12 739698 33 742691 52 745689 67 748686...   \n",
       "261                 4  2308023 17 2311014 30 2314004 49 2317000 59 23...   \n",
       "262                 4  3312310 10 3315310 11 3318301 25 3321299 27 33...   \n",
       "263                 4  793679 20 796675 32 799670 74 802662 95 805654...   \n",
       "264                 4  1430055 19 1430115 36 1433053 21 1433114 38 14...   \n",
       "265                 4  3102247 12 3105246 14 3108246 19 3111245 20 31...   \n",
       "266                 4  934450 1 937448 3 940447 3 943445 5 946444 5 9...   \n",
       "267                 4  1048080 26 1051079 28 1054078 30 1057071 39 10...   \n",
       "268                 4  1980656 1 1980673 27 1981666 48 1983655 1 1983...   \n",
       "269                 4  4173254 1 4176253 2 4179251 3 4182250 4 418524...   \n",
       "270                 4  1996630 8 1999626 14 2002624 16 2005622 19 200...   \n",
       "271                 4  2184669 23 2187667 27 2190665 31 2193661 37 21...   \n",
       "272                 4  841572 20 844566 38 847564 45 850563 50 853555...   \n",
       "273                 4  5515207 20 5518204 29 5521202 35 5524202 36 55...   \n",
       "274                 4  3270895 59 3273894 62 3276888 69 3279887 71 32...   \n",
       "275                 4  3969980 35 3970027 28 3972971 88 3975966 97 39...   \n",
       "276                 4  1611763 11 1614753 29 1617750 35 1620746 43 16...   \n",
       "277                 4  4030400 28 4033466 34 4036526 48 4039594 54 40...   \n",
       "278                 4  538473 13 541468 22 544463 30 547461 35 550459...   \n",
       "279                 4  334733 33 337729 43 340729 43 343725 51 346723...   \n",
       "280                 4  1009165 7 1012149 28 1015140 38 1018127 51 102...   \n",
       "\n",
       "      age     sex  fold  \n",
       "0    76.0    Male     4  \n",
       "1    82.0    Male     2  \n",
       "2    78.0    Male     0  \n",
       "3    68.0  Female     0  \n",
       "4    83.0    Male     1  \n",
       "5    57.0    Male     1  \n",
       "6    79.0  Female     0  \n",
       "7    60.0    Male     1  \n",
       "8    60.0    Male     2  \n",
       "9    65.0    Male     4  \n",
       "10   21.0  Female     1  \n",
       "11   41.0  Female     1  \n",
       "12   73.0    Male     1  \n",
       "13   43.0  Female     1  \n",
       "14   74.0  Female     1  \n",
       "15   84.0  Female     4  \n",
       "16   84.0    Male     4  \n",
       "17   60.0    Male     0  \n",
       "18   79.0  Female     2  \n",
       "19   57.0    Male     1  \n",
       "20   83.0    Male     0  \n",
       "21   37.0    Male     2  \n",
       "22   78.0    Male     0  \n",
       "23   74.0  Female     1  \n",
       "24   21.0    Male     0  \n",
       "25   72.0    Male     4  \n",
       "26   57.0  Female     2  \n",
       "27   73.0    Male     2  \n",
       "28   21.0    Male     0  \n",
       "29   76.0    Male     0  \n",
       "..    ...     ...   ...  \n",
       "251  37.0    Male     4  \n",
       "252  73.0    Male     4  \n",
       "253  21.0    Male     2  \n",
       "254  79.0  Female     2  \n",
       "255  37.0    Male     0  \n",
       "256  78.0    Male     2  \n",
       "257  49.0  Female     2  \n",
       "258  57.0    Male     0  \n",
       "259  83.0    Male     1  \n",
       "260  65.0  Female     1  \n",
       "261  56.0  Female     4  \n",
       "262  48.0    Male     0  \n",
       "263  84.0    Male     1  \n",
       "264  61.0    Male     1  \n",
       "265  57.0    Male     1  \n",
       "266  57.0    Male     1  \n",
       "267  55.0    Male     4  \n",
       "268  55.0    Male     2  \n",
       "269  55.0    Male     0  \n",
       "270  49.0  Female     0  \n",
       "271  57.0    Male     1  \n",
       "272  68.0  Female     4  \n",
       "273  28.0    Male     0  \n",
       "274  82.0    Male     4  \n",
       "275  61.0    Male     2  \n",
       "276  61.0    Male     1  \n",
       "277  28.0    Male     1  \n",
       "278  84.0    Male     4  \n",
       "279  28.0    Male     4  \n",
       "280  84.0    Male     4  \n",
       "\n",
       "[281 rows x 11 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"training\"><center>Training</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf fold-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf fold-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf fold-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.00e-5   00001056   30.17 | 0.746  0.089  0.0000  0.000   | 0.138  0.137   | 704.32299137115480.138  0.137   | 700.9115068912506"
     ]
    }
   ],
   "source": [
    "log.write('** start training here! **\\n')\n",
    "log.write('   batch_size = %d \\n'%(batch_size))\n",
    "log.write('                     |-------------- VALID---------|---- TRAIN/BATCH ----------------\\n')\n",
    "log.write('rate     iter  epoch | dice   loss   tp     tn     | loss           | time           \\n')\n",
    "log.write('-------------------------------------------------------------------------------------\\n')\n",
    "\n",
    "valid_loss = np.zeros(4,np.float32)\n",
    "train_loss = np.zeros(2,np.float32)\n",
    "batch_loss = np.zeros_like(train_loss)\n",
    "sum_train_loss = np.zeros_like(train_loss)\n",
    "sum_train = 0\n",
    "\n",
    "start_timer = time.time()\n",
    "iteration = start_iteration\n",
    "epoch = start_epoch\n",
    "rate = 0\n",
    "\n",
    "while iteration < num_iteration:\n",
    "    for t, batch in enumerate(train_loader):\n",
    "\n",
    "        if iteration%iter_save==0:\n",
    "            if iteration != start_iteration:\n",
    "                torch.save({\n",
    "                    'state_dict': net.state_dict(),\n",
    "                    'iteration': iteration,\n",
    "                    'epoch': epoch,\n",
    "                }, out_dir + '/checkpoint/%08d.model.pth' %  (iteration))\n",
    "                pass\n",
    "\n",
    "\n",
    "        if (iteration%iter_valid==0):\n",
    "            valid_loss = validate(net, valid_loader)\n",
    "            pass\n",
    "\n",
    "\n",
    "        if (iteration%iter_log==0) or (iteration%iter_valid==0):\n",
    "            print('\\r', end='', flush=True)\n",
    "            log.write(message(mode='log') + '\\n')\n",
    "\n",
    "\n",
    "        # learning rate schduler ------------\n",
    "        rate = get_learning_rate(optimizer)\n",
    "\n",
    "        # one iteration update  -------------\n",
    "        batch_size = len(batch['index'])\n",
    "        batch['image'] = batch['image'].half().cuda()\n",
    "        batch['mask' ] = batch['mask' ].half().cuda()\n",
    "        batch['organ'] = batch['organ'].cuda()\n",
    "\n",
    "\n",
    "        net.train()\n",
    "        net.output_type = ['loss']\n",
    "        if 1:\n",
    "            with amp.autocast(enabled = is_amp):\n",
    "                output = net(batch)\n",
    "                loss0  = output['bce_loss'].mean()\n",
    "                loss1  = output['aux2_loss'].mean()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss0+0.2*loss1).backward()\n",
    "\n",
    "            scaler.unscale_(optimizer)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "\n",
    "        # print statistics  --------\n",
    "        batch_loss[:2] = [loss0.item(),loss1.item()]\n",
    "        sum_train_loss += batch_loss\n",
    "        sum_train += 1\n",
    "        if t % 100 == 0:\n",
    "            train_loss = sum_train_loss / (sum_train + 1e-12)\n",
    "            sum_train_loss[...] = 0\n",
    "            sum_train = 0\n",
    "\n",
    "        print('\\r', end='', flush=True)\n",
    "        print(message(mode='log'), end='', flush=True)\n",
    "        epoch += 1 / len(train_loader)\n",
    "        iteration += 1\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    log.flush()\n",
    "    clear_output()\n",
    "    \n",
    "log.write('\\n')\n",
    "log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf fold-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
