{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height:200px;width:100%;margin: 0;\">\n",
    "    <img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/34547/logos/header.png?t=2022-02-15-22-37-27\" style=\"width:100%;\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"credits\"><center>Credits</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the reverse engineering of the [hengck23 discussion](https://www.kaggle.com/code/hengck23/lb-0-75-variable-size-swin-transformer-v1-and-v2).<br>\n",
    "Please upvote both discussion/notebooks if you are planning to use Swin Transformers or any part of the code.\n",
    "\n",
    "**hengck23 owner Disclaimer**\n",
    "\n",
    "[1] the code is taken from a larger project and is by no means complete. It will has missing import modules, etc. But these are trival functions that you can ignore or fill in yourself.\n",
    "\n",
    "[2] you are free to use, modify the code for your own notebook or submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"imports\"><center>Imports</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.cuda.amp as amp\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import RandomSampler \n",
    "from torch.utils.data import SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional import dice_score\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "is_amp = True\n",
    "import logging\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import numpy as np\n",
    "from itertools import repeat\n",
    "import collections.abc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"paths\"><center>Paths</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip archive\\(2\\).zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_dir = '.'\n",
    "root_dir = '.'\n",
    "\n",
    "TRAIN = '../data/train_images_768/'\n",
    "MASKS = '../data/train_masks_768/'\n",
    "LABELS = '../data/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./../data/train_masks_768/10044.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.min(), data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"additionals\"><center>Additionals</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "def image_to_tensor(image, mode='bgr'): #image mode\n",
    "    if mode=='bgr':\n",
    "        image = image[:,:,::-1]\n",
    "    x = image\n",
    "    x = x.transpose(2,0,1)\n",
    "    x = np.ascontiguousarray(x)\n",
    "    x = torch.tensor(x, dtype=torch.float)\n",
    "    return x\n",
    "\n",
    "\n",
    "def mask_to_tensor(mask):\n",
    "    x = mask\n",
    "    x = torch.tensor(x, dtype=torch.float)\n",
    "    return x\n",
    "\n",
    "\n",
    "tensor_list = ['mask', 'image', 'organ']\n",
    "\n",
    "def null_collate(batch):\n",
    "    d = {}\n",
    "    key = batch[0].keys()\n",
    "    for k in key:\n",
    "        v = [b[k] for b in batch]\n",
    "        if k in tensor_list:\n",
    "            v = torch.stack(v)\n",
    "        d[k] = v\n",
    "\n",
    "    d['mask'] = d['mask'].unsqueeze(1)\n",
    "    d['organ'] = d['organ'].reshape(-1)\n",
    "    return d\n",
    "\n",
    "\n",
    "def _ntuple(n):\n",
    "    def parse(x):\n",
    "        if isinstance(x, collections.abc.Iterable):\n",
    "            return x\n",
    "        return tuple(repeat(x, n))\n",
    "    return parse\n",
    "\n",
    "\n",
    "to_2tuple = _ntuple(2)\n",
    "\n",
    "\n",
    "def _no_grad_trunc_normal_(tensor, mean, std, a, b):\n",
    "    # Cut & paste from PyTorch official master until it's in a few official releases - RW\n",
    "    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n",
    "    def norm_cdf(x):\n",
    "        # Computes standard normal cumulative distribution function\n",
    "        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n",
    "\n",
    "    if (mean < a - 2 * std) or (mean > b + 2 * std):\n",
    "        warnings.warn(\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"\n",
    "                      \"The distribution of values may be incorrect.\",\n",
    "                      stacklevel=2)\n",
    "\n",
    "        \n",
    "def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n",
    "    return _no_grad_trunc_normal_(tensor, mean, std, a, b)\n",
    "\n",
    "\n",
    "def drop_path(x, drop_prob: float = 0., training: bool = False, scale_by_keep: bool = True):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n",
    "    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n",
    "    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n",
    "    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n",
    "    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n",
    "    'survival rate' as the argument.\n",
    "    \"\"\"\n",
    "    if drop_prob == 0. or not training:\n",
    "        return x\n",
    "    keep_prob = 1 - drop_prob\n",
    "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
    "    random_tensor = x.new_empty(shape).bernoulli_(keep_prob)\n",
    "    if keep_prob > 0.0 and scale_by_keep:\n",
    "        random_tensor.div_(keep_prob)\n",
    "    return x * random_tensor\n",
    "\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
    "    \"\"\"\n",
    "    def __init__(self, drop_prob: float = 0., scale_by_keep: bool = True):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.scale_by_keep = scale_by_keep\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training, self.scale_by_keep)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f'drop_prob={round(self.drop_prob,3):0.3f}'\n",
    "    \n",
    "    \n",
    "class RGB(nn.Module):\n",
    "    IMAGE_RGB_MEAN = [0.485, 0.456, 0.406] #[0.5, 0.5, 0.5]\n",
    "    IMAGE_RGB_STD  = [0.229, 0.224, 0.225] #[0.5, 0.5, 0.5]\n",
    "\n",
    "    def __init__(self,):\n",
    "        super(RGB, self).__init__()\n",
    "        self.register_buffer('mean', torch.zeros(1,3,1,1))\n",
    "        self.register_buffer('std', torch.ones(1,3,1,1))\n",
    "        self.mean.data = torch.FloatTensor(self.IMAGE_RGB_MEAN).view(self.mean.shape)\n",
    "        self.std.data = torch.FloatTensor(self.IMAGE_RGB_STD).view(self.std.shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = (x-self.mean)/self.std\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def message(mode='print'):\n",
    "    asterisk = ' '\n",
    "    if mode==('print'):\n",
    "        loss = batch_loss\n",
    "    if mode==('log'):\n",
    "        loss = train_loss\n",
    "        if (iteration % iter_save == 0): asterisk = '*'\n",
    "\n",
    "    text = \\\n",
    "        ('%0.2e   %08d%s %6.2f | '%(rate, iteration, asterisk, epoch,)).replace('e-0','e-').replace('e+0','e+') + \\\n",
    "        '%4.3f  %4.3f  %4.4f  %4.3f   | '%(*valid_loss,) + \\\n",
    "        '%4.3f  %4.3f   | '%(*loss,) + \\\n",
    "        '%s' % ((time.time() - start_timer))\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"randoms\"><center>Random choice</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_augment5(image, mask, organ):\n",
    "    #image, mask  = do_crop(image, mask, image_size, xy=(None,None))\n",
    "    return image, mask\n",
    "\n",
    "def train_augment5b(image, mask, organ):\n",
    "    image, mask = do_random_flip(image, mask)\n",
    "    image, mask = do_random_rot90(image, mask)\n",
    "\n",
    "    for fn in np.random.choice([\n",
    "        lambda image, mask: (image, mask),\n",
    "        lambda image, mask: do_random_noise(image, mask, mag=0.1),\n",
    "        lambda image, mask: do_random_contast(image, mask, mag=0.40),\n",
    "        lambda image, mask: do_random_hsv(image, mask, mag=[0.40, 0.40, 0])\n",
    "    ], 2): image, mask = fn(image, mask)\n",
    "\n",
    "    for fn in np.random.choice([\n",
    "        lambda image, mask: (image, mask),\n",
    "        lambda image, mask: do_random_rotate_scale(image, mask, angle=45, scale=[0.50, 2.0]),\n",
    "    ], 1): image, mask = fn(image, mask)\n",
    "\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"augmentations\"><center>Augmentations</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "def do_random_flip(image, mask):\n",
    "    if np.random.rand()>0.5:\n",
    "        image = cv2.flip(image,0)\n",
    "        mask = cv2.flip(mask,0)\n",
    "    if np.random.rand()>0.5:\n",
    "        image = cv2.flip(image,1)\n",
    "        mask = cv2.flip(mask,1)\n",
    "    if np.random.rand()>0.5:\n",
    "        image = image.transpose(1,0,2)\n",
    "        mask = mask.transpose(1,0)\n",
    "    \n",
    "    image = np.ascontiguousarray(image)\n",
    "    mask = np.ascontiguousarray(mask)\n",
    "    return image, mask\n",
    "\n",
    "def do_random_rot90(image, mask):\n",
    "    r = np.random.choice([\n",
    "        0,\n",
    "        cv2.ROTATE_90_CLOCKWISE,\n",
    "        cv2.ROTATE_90_COUNTERCLOCKWISE,\n",
    "        cv2.ROTATE_180,\n",
    "    ])\n",
    "    if r==0:\n",
    "        return image, mask\n",
    "    else:\n",
    "        image = cv2.rotate(image, r)\n",
    "        mask = cv2.rotate(mask, r)\n",
    "        return image, mask\n",
    "    \n",
    "def do_random_contast(image, mask, mag=0.3):\n",
    "    alpha = 1 + random.uniform(-1,1)*mag\n",
    "    image = image * alpha\n",
    "    image = np.clip(image,0,1)\n",
    "    return image, mask\n",
    "\n",
    "def do_random_hsv(image, mask, mag=[0.15,0.25,0.25]):\n",
    "    image = (image*255).astype(np.uint8)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    h = hsv[:, :, 0].astype(np.float32)  # hue\n",
    "    s = hsv[:, :, 1].astype(np.float32)  # saturation\n",
    "    v = hsv[:, :, 2].astype(np.float32)  # value\n",
    "    h = (h*(1 + random.uniform(-1,1)*mag[0]))%180\n",
    "    s =  s*(1 + random.uniform(-1,1)*mag[1])\n",
    "    v =  v*(1 + random.uniform(-1,1)*mag[2])\n",
    "\n",
    "    hsv[:, :, 0] = np.clip(h,0,180).astype(np.uint8)\n",
    "    hsv[:, :, 1] = np.clip(s,0,255).astype(np.uint8)\n",
    "    hsv[:, :, 2] = np.clip(v,0,255).astype(np.uint8)\n",
    "    image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    image = image.astype(np.float32)/255\n",
    "    return image, mask\n",
    "\n",
    "def do_random_noise(image, mask, mag=0.1):\n",
    "    height, width = image.shape[:2]\n",
    "    noise = np.random.uniform(-1,1, (height, width,1))*mag\n",
    "    image = image + noise\n",
    "    image = np.clip(image,0,1)\n",
    "    return image, mask\n",
    "\n",
    "def do_random_rotate_scale(image, mask, angle=30, scale=[0.8,1.2] ):\n",
    "    angle = np.random.uniform(-angle, angle)\n",
    "    scale = np.random.uniform(*scale) if scale is not None else 1\n",
    "    \n",
    "    height, width = image.shape[:2]\n",
    "    center = (height // 2, width // 2)\n",
    "    \n",
    "    transform = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    image = cv2.warpAffine( image, transform, (width, height), flags=cv2.INTER_LINEAR,\n",
    "                            borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))\n",
    "    mask  = cv2.warpAffine( mask, transform, (width, height), flags=cv2.INTER_LINEAR,\n",
    "                            borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"dataset\"><center>Dataset</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 768\n",
    "\n",
    "class HubmapDataset(Dataset):\n",
    "    def __init__(self, df, augment=None):\n",
    "\n",
    "        self.df = df\n",
    "        self.augment = augment\n",
    "        self.length = len(self.df)\n",
    "        ids = pd.read_csv(LABELS).id.astype(str).values\n",
    "        self.fnames = [fname for fname in os.listdir(TRAIN)]# if fname.split('_')[0] in ids]\n",
    "        self.organ_to_label = {'kidney' : 0,\n",
    "                               'prostate' : 1,\n",
    "                               'largeintestine' : 2,\n",
    "                               'spleen' : 3,\n",
    "                               'lung' : 4}\n",
    "\n",
    "    def __str__(self):\n",
    "        string = ''\n",
    "        string += '\\tlen = %d\\n' % len(self)\n",
    "\n",
    "        d = self.df.organ.value_counts().to_dict()\n",
    "        for k in ['kidney', 'prostate', 'largeintestine', 'spleen', 'lung']:\n",
    "            string +=  '%24s %3d (%0.3f) \\n'%(k,d.get(k,0),d.get(k,0)/len(self.df))\n",
    "        return string\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fname = self.fnames[index]\n",
    "        d = self.df.iloc[index]\n",
    "        organ = self.organ_to_label[d.organ]\n",
    "\n",
    "        image = cv2.cvtColor(cv2.imread(os.path.join(TRAIN,fname)), cv2.COLOR_BGR2RGB)\n",
    "#         mask = cv2.imread(os.path.join(MASKS,fname),cv2.IMREAD_GRAYSCALE)\n",
    "        mask = np.load(os.path.join(MASKS,fname.replace('.png', '.npy')),cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        \n",
    "        image = image.astype(np.float32)/255\n",
    "        mask  = mask.astype(np.float32) #/255\n",
    "\n",
    "#         s = d.pixel_size/0.4 * (image_size/3000)\n",
    "        image = cv2.resize(image,dsize=(image_size,image_size),interpolation=cv2.INTER_LINEAR)\n",
    "        mask  = cv2.resize(mask, dsize=(image_size,image_size),interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        if self.augment is not None:\n",
    "            image, mask = self.augment(image, mask, organ)\n",
    "\n",
    "\n",
    "        r ={}\n",
    "        r['index']= index\n",
    "        r['id'] = fname\n",
    "        r['organ'] = torch.tensor([organ], dtype=torch.long)\n",
    "        r['image'] = image_to_tensor(image)\n",
    "        r['mask' ] = mask_to_tensor(mask>0.5)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"patching\"><center>NETWORK</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "from swintransformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "def run_check_net():\n",
    "    batch_size = 2\n",
    "    image_size = 512\n",
    "\n",
    "    #---\n",
    "    batch = {\n",
    "        'image' : torch.from_numpy( np.random.uniform(-1,1,(batch_size,3,image_size,image_size)) ).float(),\n",
    "        'mask'  : torch.from_numpy( np.random.choice(2,(batch_size,1,image_size,image_size)) ).float(),\n",
    "        'organ' : torch.from_numpy( np.random.choice(5,(batch_size)) ).long(),\n",
    "    }\n",
    "    batch = {k:v.cuda() for k,v in batch.items()}\n",
    "\n",
    "    net = Net().cuda()\n",
    "    net.load_pretrain()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            output = net(batch)\n",
    "\n",
    "    print('batch')\n",
    "    for k,v in batch.items():\n",
    "        print('%32s :'%k, v.shape)\n",
    "\n",
    "    print('output')\n",
    "    for k,v in output.items():\n",
    "        if 'loss' not in k:\n",
    "            print('%32s :'%k, v.shape)\n",
    "    for k,v in output.items():\n",
    "        if 'loss' in k:\n",
    "            print('%32s :'%k, v.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = dict(\n",
    "\n",
    "        #configs/_base_/models/upernet_swin.py\n",
    "        basic = dict(\n",
    "            swin=dict(\n",
    "                embed_dim=96,\n",
    "                depths=[2, 2, 6, 2],\n",
    "                num_heads=[3, 6, 12, 24],\n",
    "                window_size=7,\n",
    "                mlp_ratio=4.,\n",
    "                qkv_bias=True,\n",
    "                qk_scale=None,\n",
    "                drop_rate=0.,\n",
    "                attn_drop_rate=0.,\n",
    "                drop_path_rate=0.3,\n",
    "                ape=False,\n",
    "                patch_norm=True,\n",
    "                out_indices=(0, 1, 2, 3),\n",
    "                use_checkpoint=False\n",
    "            ),\n",
    "\n",
    "        ),\n",
    "\n",
    "        #configs/swin/upernet_swin_tiny_patch4_window7_512x512_160k_ade20k.py\n",
    "        swin_tiny_patch4_window7_224=dict(\n",
    "            checkpoint = pretrain_dir+'/swin_tiny_patch4_window7_224_22k.pth',\n",
    "\n",
    "            swin = dict(\n",
    "                embed_dim=96,\n",
    "                depths=[2, 2, 6, 2],\n",
    "                num_heads=[3, 6, 12, 24],\n",
    "                window_size=7,\n",
    "                ape=False,\n",
    "                drop_path_rate=0.3,\n",
    "                patch_norm=True,\n",
    "                use_checkpoint=False,\n",
    "            ),\n",
    "            upernet=dict(\n",
    "                in_channels=[96, 192, 384, 768],\n",
    "            ),\n",
    "        ),\n",
    "\n",
    "        #/configs/swin/upernet_swin_small_patch4_window7_512x512_160k_ade20k.py\n",
    "        swin_small_patch4_window7_224_22k=dict(\n",
    "            checkpoint = pretrain_dir+'/swin_small_patch4_window7_224_22k.pth',\n",
    "\n",
    "            swin = dict(\n",
    "                embed_dim=96,\n",
    "                depths=[2, 2, 18, 2],\n",
    "                num_heads=[3, 6, 12, 24],\n",
    "                window_size=7,\n",
    "                ape=False,\n",
    "                drop_path_rate=0.3,\n",
    "                patch_norm=True,\n",
    "                use_checkpoint=False\n",
    "            ),\n",
    "            upernet=dict(\n",
    "                in_channels=[96, 192, 384, 768],\n",
    "            ),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"folds\"><center>Folds</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fold(fold=0):\n",
    "    df = pd.read_csv(root_dir + '/../data/train.csv')\n",
    "\n",
    "    num_fold = 5\n",
    "    skf = KFold(n_splits=num_fold, shuffle=True,random_state=42)\n",
    "\n",
    "    df.loc[:,'fold']=-1\n",
    "    for f,(t_idx, v_idx) in enumerate(skf.split(X=df['id'], y=df['organ'])):\n",
    "        df.iloc[v_idx,-1]=f\n",
    "\n",
    "    #check\n",
    "    if 0:\n",
    "        for f in range(num_fold):\n",
    "            train_df=df[df.fold!=f].reset_index(drop=True)\n",
    "            valid_df=df[df.fold==f].reset_index(drop=True)\n",
    "\n",
    "            print('fold %d'%f)\n",
    "            t = train_df.organ.value_counts().to_dict()\n",
    "            v = valid_df.organ.value_counts().to_dict()\n",
    "            for k in ['kidney', 'prostate', 'largeintestine', 'spleen', 'lung']:\n",
    "                print('%32s %3d (%0.3f)  %3d (%0.3f)'%(k,t.get(k,0),t.get(k,0)/len(train_df),v.get(k,0),v.get(k,0)/len(valid_df)))\n",
    "\n",
    "            print('')\n",
    "            zz=0\n",
    "\n",
    "    train_df=df[df.fold!=fold].reset_index(drop=True)\n",
    "    valid_df=df[df.fold==fold].reset_index(drop=True)\n",
    "    return train_df,valid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"dice_score\"><center>Competition Metric</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dice_score(probability, mask):\n",
    "    N = len(probability)\n",
    "    p = probability.reshape(N,-1)\n",
    "    t = mask.reshape(N,-1)\n",
    "\n",
    "    p = p>0.5\n",
    "    t = t>0.5\n",
    "    uion = p.sum(-1) + t.sum(-1)\n",
    "    overlap = (p*t).sum(-1)\n",
    "    dice = 2*overlap/(uion+0.0001)\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"validation\"><center>Validation</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net, valid_loader):\n",
    "\n",
    "    valid_num = 0\n",
    "    valid_probability = []\n",
    "    valid_mask = []\n",
    "    valid_loss = 0\n",
    "\n",
    "    net = net.eval()\n",
    "    start_timer = time.time()\n",
    "    for t, batch in enumerate(valid_loader):\n",
    "\n",
    "        net.output_type = ['loss', 'inference']\n",
    "        with torch.no_grad():\n",
    "            with amp.autocast(enabled = is_amp):\n",
    "\n",
    "                batch_size = len(batch['index'])\n",
    "                batch['image'] = batch['image'].cuda()\n",
    "                batch['mask' ] = batch['mask' ].cuda()\n",
    "                batch['organ'] = batch['organ'].cuda()\n",
    "\n",
    "                output = net(batch)\n",
    "                loss0  = output['bce_loss'].mean()\n",
    "\n",
    "        valid_probability.append(output['probability'].data.cpu().numpy())\n",
    "        valid_mask.append(batch['mask'].data.cpu().numpy())\n",
    "        valid_num += batch_size\n",
    "        valid_loss += batch_size*loss0.item()\n",
    "\n",
    "        #debug\n",
    "        if 0 :\n",
    "            pass\n",
    "            organ = batch['organ'].data.cpu().numpy()\n",
    "            image = batch['image']\n",
    "            mask  = batch['mask']\n",
    "            probability  = output['probability']\n",
    "\n",
    "            for b in range(batch_size):\n",
    "                m = tensor_to_image(image[b])\n",
    "                t = tensor_to_mask(mask[b,0])\n",
    "                p = tensor_to_mask(probability[b,0])\n",
    "                overlay = result_to_overlay(m, t, p )\n",
    "\n",
    "                text = label_to_organ[organ[b]]\n",
    "                draw_shadow_text(overlay,text,(5,15),0.7,(1,1,1),1)\n",
    "\n",
    "                image_show_norm('overlay',overlay,min=0,max=1,resize=1)\n",
    "                cv2.waitKey(0)\n",
    "\n",
    "        print('\\r %8d / %d  %s'%(valid_num, len(valid_loader.dataset),(time.time() - start_timer)),end='',flush=True)\n",
    "\n",
    "    assert(valid_num == len(valid_loader.dataset))\n",
    "\n",
    "    probability = np.concatenate(valid_probability)\n",
    "    mask = np.concatenate(valid_mask)\n",
    "\n",
    "    loss = valid_loss/valid_num\n",
    "\n",
    "    dice = compute_dice_score(probability, mask)\n",
    "    dice = dice.mean()\n",
    "    \n",
    "    return [dice, loss,  0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"init\"><center>Initialization</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learning_rate(optimizer):\n",
    "    return optimizer.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./swin_tiny_patch4_window7_224_22k.pth ...\n",
      "_IncompatibleKeys(missing_keys=['out_norm.0.weight', 'out_norm.0.bias', 'out_norm.1.weight', 'out_norm.1.bias', 'out_norm.2.weight', 'out_norm.2.bias', 'out_norm.3.weight', 'out_norm.3.bias'], unexpected_keys=['norm.weight', 'norm.bias', 'head.weight', 'head.bias', 'layers.0.blocks.1.attn_mask', 'layers.1.blocks.1.attn_mask', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.5.attn_mask'])\n"
     ]
    }
   ],
   "source": [
    "fold = FOLD\n",
    "\n",
    "out_dir = root_dir + '/fold-%d' % (fold)\n",
    "initial_checkpoint = None\n",
    "\n",
    "start_lr   = 5e-5 #0.0001\n",
    "batch_size = 8 #32 #32\n",
    "\n",
    "\n",
    "## setup  ----------------------------------------\n",
    "for f in ['checkpoint','train','valid','backup'] : os.makedirs(out_dir +'/'+f, exist_ok=True)\n",
    "\n",
    "    \n",
    "log = open(out_dir+'/log.train.txt',mode='a')\n",
    "log.write('\\n--- [START %s] %s\\n\\n' % ('Swin', '-' * 64))\n",
    "log.write('\\n')\n",
    "\n",
    "\n",
    "## dataset ----------------------------------------\n",
    "log.write('** dataset setting **\\n')\n",
    "\n",
    "train_df, valid_df = make_fold(fold)\n",
    "\n",
    "train_dataset = HubmapDataset(train_df, train_augment5b)\n",
    "valid_dataset = HubmapDataset(valid_df, valid_augment5)\n",
    "\n",
    "train_loader  = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler = RandomSampler(train_dataset),\n",
    "    batch_size  = batch_size,\n",
    "    drop_last   = True,\n",
    "    num_workers = 8,\n",
    "    pin_memory  = False,\n",
    "    worker_init_fn = lambda id: np.random.seed(torch.initial_seed() // 2 ** 32 + id),\n",
    "    collate_fn = null_collate,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    sampler = SequentialSampler(valid_dataset),\n",
    "    batch_size  = 8,\n",
    "    drop_last   = False,\n",
    "    num_workers = 4,\n",
    "    pin_memory  = False,\n",
    "    collate_fn = null_collate,\n",
    ")\n",
    "\n",
    "\n",
    "log.write('fold = %s\\n'%str(fold))\n",
    "log.write('train_dataset : \\n%s\\n'%(train_dataset))\n",
    "log.write('valid_dataset : \\n%s\\n'%(valid_dataset))\n",
    "log.write('\\n')\n",
    "\n",
    "\n",
    "## net ----------------------------------------\n",
    "log.write('** net setting **\\n')\n",
    "\n",
    "scaler = amp.GradScaler(enabled = is_amp)\n",
    "net = Net(cfg).cuda()\n",
    "\n",
    "if initial_checkpoint is not None:\n",
    "    f = torch.load(initial_checkpoint, map_location=lambda storage, loc: storage)\n",
    "    start_iteration = f['iteration']\n",
    "    start_epoch = f['epoch']\n",
    "    state_dict  = f['state_dict']\n",
    "    net.load_state_dict(state_dict,strict=False)  #True\n",
    "else:\n",
    "    start_iteration = 0\n",
    "    start_epoch = 0\n",
    "    net.load_pretrain()\n",
    "\n",
    "\n",
    "log.write('\\tinitial_checkpoint = %s\\n' % initial_checkpoint)\n",
    "log.write('\\n')\n",
    "\n",
    "\n",
    "## optimiser ----------------------------------\n",
    "if 0: ##freeze\n",
    "    for p in net.stem.parameters():   p.requires_grad = False\n",
    "    pass\n",
    "\n",
    "def freeze_bn(net):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            m.eval()\n",
    "            m.weight.requires_grad = False\n",
    "            m.bias.requires_grad = False\n",
    "            \n",
    "#freeze_bn(net)\n",
    "\n",
    "#-----------------------------------------------\n",
    "\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, net.parameters()),lr=start_lr)\n",
    "\n",
    "log.write('optimizer\\n  %s\\n'%(optimizer))\n",
    "log.write('\\n')\n",
    "\n",
    "num_iteration = 1000*len(train_loader)\n",
    "iter_log   = len(train_loader)*3 #479\n",
    "iter_valid = iter_log\n",
    "iter_save  = iter_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>organ</th>\n",
       "      <th>data_source</th>\n",
       "      <th>img_height</th>\n",
       "      <th>img_width</th>\n",
       "      <th>pixel_size</th>\n",
       "      <th>tissue_thickness</th>\n",
       "      <th>rle</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10044</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1459676 77 1462675 82 1465674 87 1468673 92 14...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10392</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1228631 20 1231629 24 1234624 40 1237623 47 12...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10488</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3446519 15 3449517 17 3452514 20 3455510 24 34...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10610</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>478925 68 481909 87 484893 105 487863 154 4908...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10611</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>730193 18 733191 25 736191 25 739152 65 742149...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10651</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1240229 12 1243227 15 1246223 26 1249221 29 12...</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10666</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2698231 7 2701231 7 2704226 16 2707221 25 2710...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10703</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>811259 262 814258 264 817257 266 820256 267 82...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10892</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>523786 3 526784 8 529782 8 532778 9 535642 25 ...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10912</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1147323 50 1150316 59 1153309 68 1156303 76 11...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10971</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1507862 60 1510857 69 1513853 77 1516848 86 15...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10992</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2245542 37 2248540 41 2251534 53 2254533 55 22...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1123</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2852439 100 2855436 106 2858434 110 2861421 13...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11448</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3450282 28 3453278 33 3456272 53 3459271 56 34...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11497</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>940436 51 943430 65 946427 76 949423 89 952417...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1157</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4883571 15 4886565 32 4889561 41 4892559 49 48...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11629</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4143554 1 4146554 2 4149554 3 4152555 3 415555...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11645</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>2867</td>\n",
       "      <td>2867</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1971766 32 1974633 34 1977499 36 1980366 37 19...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1184</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1916384 12 1919383 15 1922378 26 1925376 29 19...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11890</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1297230 32 1300222 46 1303215 60 1306213 63 13...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>12026</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>568261 32 571258 36 574256 38 577245 61 580243...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12174</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>592530 6 595511 36 598506 43 601493 63 604487 ...</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1220</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1429797 16 1432793 21 1435791 23 1438789 27 14...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12233</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>733853 11 736851 15 739841 44 742839 47 745790...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12244</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1195159 3 1195187 56 1198157 7 1198185 59 1201...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1229</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>2654</td>\n",
       "      <td>2654</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>229957 31 232610 33 235217 84 237869 87 240521...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12452</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4648688 22 4651675 37 4654675 39 4657670 48 46...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12466</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>920222 4 923221 6 926221 6 929220 10 932218 14...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12471</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>472548 109 475547 111 478539 2 478546 118 4815...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12476</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2783561 23 2786559 26 2789558 28 2792556 31 27...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>6807</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1588425 13 1591421 23 1594418 37 1597415 49 16...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>686</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3032126 43 3035125 44 3038123 47 3041122 50 30...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>7359</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4020786 16 4023785 22 4026784 27 4029782 31 40...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>737</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2970903 20 2973901 24 2976888 43 2979884 48 29...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>7397</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3160782 56 3163780 60 3166779 62 3169777 65 31...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>7569</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2270333 17 2273328 25 2276318 45 2279314 52 22...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>7706</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>799394 14 802393 17 805392 19 808391 34 811389...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>8116</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>994719 76 997717 79 1000711 103 1003709 110 10...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>8151</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2057037 10 2060034 13 2063031 17 2066027 21 20...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>8222</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>165901 31 168900 33 171891 44 174890 47 177888...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>8227</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>529710 25 532708 28 535700 40 538699 43 541698...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>8231</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3707337 1 3710337 2 3713336 4 3716336 6 371933...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>8343</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2170394 3 2173394 6 2176394 7 2179395 7 218239...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>8388</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2989254 26 2992254 28 2995251 35 2998246 45 30...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>8402</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>679462 5 682457 13 685448 25 685504 27 688447 ...</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>8450</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>736706 12 739698 33 742691 52 745689 67 748686...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>8638</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3312310 10 3315310 11 3318301 25 3321299 27 33...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>8752</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>793679 20 796675 32 799670 74 802662 95 805654...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>8842</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1430055 19 1430115 36 1433053 21 1433114 38 14...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>8876</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3102247 12 3105246 14 3108246 19 3111245 20 31...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>8894</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>934450 1 937448 3 940447 3 943445 5 946444 5 9...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>928</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1980656 1 1980673 27 1981666 48 1983655 1 1983...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>9358</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4173254 1 4176253 2 4179251 3 4182250 4 418524...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>9387</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1996630 8 1999626 14 2002624 16 2005622 19 200...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>9407</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2184669 23 2187667 27 2190665 31 2193661 37 21...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>9445</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>5515207 20 5518204 29 5521202 35 5524202 36 55...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>9450</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>2675</td>\n",
       "      <td>2675</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1779826 5 1782499 8 1785172 11 1787845 14 1790...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>9470</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3969980 35 3970027 28 3972971 88 3975966 97 39...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>9517</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1611763 11 1614753 29 1617750 35 1620746 43 16...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>9769</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3070</td>\n",
       "      <td>3070</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4030400 28 4033466 34 4036526 48 4039594 54 40...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id           organ data_source  img_height  img_width  pixel_size  \\\n",
       "0    10044        prostate         HPA        3000       3000         0.4   \n",
       "1    10392          spleen         HPA        3000       3000         0.4   \n",
       "2    10488            lung         HPA        3000       3000         0.4   \n",
       "3    10610          spleen         HPA        3000       3000         0.4   \n",
       "4    10611          kidney         HPA        3000       3000         0.4   \n",
       "5    10651  largeintestine         HPA        3000       3000         0.4   \n",
       "6    10666        prostate         HPA        3000       3000         0.4   \n",
       "7    10703          spleen         HPA        3000       3000         0.4   \n",
       "8    10892  largeintestine         HPA        3000       3000         0.4   \n",
       "9    10912        prostate         HPA        3000       3000         0.4   \n",
       "10   10971        prostate         HPA        3000       3000         0.4   \n",
       "11   10992          spleen         HPA        3000       3000         0.4   \n",
       "12    1123          spleen         HPA        3000       3000         0.4   \n",
       "13   11448          spleen         HPA        3000       3000         0.4   \n",
       "14   11497          kidney         HPA        3000       3000         0.4   \n",
       "15    1157          kidney         HPA        3000       3000         0.4   \n",
       "16   11629            lung         HPA        3000       3000         0.4   \n",
       "17   11645          spleen         HPA        2867       2867         0.4   \n",
       "18    1184        prostate         HPA        3000       3000         0.4   \n",
       "19   11890  largeintestine         HPA        3000       3000         0.4   \n",
       "20   12026          spleen         HPA        3000       3000         0.4   \n",
       "21   12174  largeintestine         HPA        3000       3000         0.4   \n",
       "22    1220            lung         HPA        3000       3000         0.4   \n",
       "23   12233        prostate         HPA        3000       3000         0.4   \n",
       "24   12244        prostate         HPA        3000       3000         0.4   \n",
       "25    1229        prostate         HPA        2654       2654         0.4   \n",
       "26   12452            lung         HPA        3000       3000         0.4   \n",
       "27   12466          spleen         HPA        3000       3000         0.4   \n",
       "28   12471  largeintestine         HPA        3000       3000         0.4   \n",
       "29   12476            lung         HPA        3000       3000         0.4   \n",
       "..     ...             ...         ...         ...        ...         ...   \n",
       "251   6807          kidney         HPA        3000       3000         0.4   \n",
       "252    686            lung         HPA        3000       3000         0.4   \n",
       "253   7359            lung         HPA        3000       3000         0.4   \n",
       "254    737        prostate         HPA        3000       3000         0.4   \n",
       "255   7397        prostate         HPA        3000       3000         0.4   \n",
       "256   7569          kidney         HPA        3000       3000         0.4   \n",
       "257   7706        prostate         HPA        3000       3000         0.4   \n",
       "258   8116          spleen         HPA        3000       3000         0.4   \n",
       "259   8151            lung         HPA        3000       3000         0.4   \n",
       "260   8222  largeintestine         HPA        3000       3000         0.4   \n",
       "261   8227        prostate         HPA        3000       3000         0.4   \n",
       "262   8231            lung         HPA        3000       3000         0.4   \n",
       "263   8343            lung         HPA        3000       3000         0.4   \n",
       "264   8388        prostate         HPA        3000       3000         0.4   \n",
       "265   8402  largeintestine         HPA        3000       3000         0.4   \n",
       "266   8450  largeintestine         HPA        3000       3000         0.4   \n",
       "267   8638        prostate         HPA        3000       3000         0.4   \n",
       "268   8752  largeintestine         HPA        3000       3000         0.4   \n",
       "269   8842        prostate         HPA        3000       3000         0.4   \n",
       "270   8876          spleen         HPA        3000       3000         0.4   \n",
       "271   8894          spleen         HPA        3000       3000         0.4   \n",
       "272    928        prostate         HPA        3000       3000         0.4   \n",
       "273   9358        prostate         HPA        3000       3000         0.4   \n",
       "274   9387            lung         HPA        3000       3000         0.4   \n",
       "275   9407          spleen         HPA        3000       3000         0.4   \n",
       "276   9445          kidney         HPA        3000       3000         0.4   \n",
       "277   9450            lung         HPA        2675       2675         0.4   \n",
       "278   9470          kidney         HPA        3000       3000         0.4   \n",
       "279   9517          kidney         HPA        3000       3000         0.4   \n",
       "280   9769          kidney         HPA        3070       3070         0.4   \n",
       "\n",
       "     tissue_thickness                                                rle  \\\n",
       "0                   4  1459676 77 1462675 82 1465674 87 1468673 92 14...   \n",
       "1                   4  1228631 20 1231629 24 1234624 40 1237623 47 12...   \n",
       "2                   4  3446519 15 3449517 17 3452514 20 3455510 24 34...   \n",
       "3                   4  478925 68 481909 87 484893 105 487863 154 4908...   \n",
       "4                   4  730193 18 733191 25 736191 25 739152 65 742149...   \n",
       "5                   4  1240229 12 1243227 15 1246223 26 1249221 29 12...   \n",
       "6                   4  2698231 7 2701231 7 2704226 16 2707221 25 2710...   \n",
       "7                   4  811259 262 814258 264 817257 266 820256 267 82...   \n",
       "8                   4  523786 3 526784 8 529782 8 532778 9 535642 25 ...   \n",
       "9                   4  1147323 50 1150316 59 1153309 68 1156303 76 11...   \n",
       "10                  4  1507862 60 1510857 69 1513853 77 1516848 86 15...   \n",
       "11                  4  2245542 37 2248540 41 2251534 53 2254533 55 22...   \n",
       "12                  4  2852439 100 2855436 106 2858434 110 2861421 13...   \n",
       "13                  4  3450282 28 3453278 33 3456272 53 3459271 56 34...   \n",
       "14                  4  940436 51 943430 65 946427 76 949423 89 952417...   \n",
       "15                  4  4883571 15 4886565 32 4889561 41 4892559 49 48...   \n",
       "16                  4  4143554 1 4146554 2 4149554 3 4152555 3 415555...   \n",
       "17                  4  1971766 32 1974633 34 1977499 36 1980366 37 19...   \n",
       "18                  4  1916384 12 1919383 15 1922378 26 1925376 29 19...   \n",
       "19                  4  1297230 32 1300222 46 1303215 60 1306213 63 13...   \n",
       "20                  4  568261 32 571258 36 574256 38 577245 61 580243...   \n",
       "21                  4  592530 6 595511 36 598506 43 601493 63 604487 ...   \n",
       "22                  4  1429797 16 1432793 21 1435791 23 1438789 27 14...   \n",
       "23                  4  733853 11 736851 15 739841 44 742839 47 745790...   \n",
       "24                  4  1195159 3 1195187 56 1198157 7 1198185 59 1201...   \n",
       "25                  4  229957 31 232610 33 235217 84 237869 87 240521...   \n",
       "26                  4  4648688 22 4651675 37 4654675 39 4657670 48 46...   \n",
       "27                  4  920222 4 923221 6 926221 6 929220 10 932218 14...   \n",
       "28                  4  472548 109 475547 111 478539 2 478546 118 4815...   \n",
       "29                  4  2783561 23 2786559 26 2789558 28 2792556 31 27...   \n",
       "..                ...                                                ...   \n",
       "251                 4  1588425 13 1591421 23 1594418 37 1597415 49 16...   \n",
       "252                 4  3032126 43 3035125 44 3038123 47 3041122 50 30...   \n",
       "253                 4  4020786 16 4023785 22 4026784 27 4029782 31 40...   \n",
       "254                 4  2970903 20 2973901 24 2976888 43 2979884 48 29...   \n",
       "255                 4  3160782 56 3163780 60 3166779 62 3169777 65 31...   \n",
       "256                 4  2270333 17 2273328 25 2276318 45 2279314 52 22...   \n",
       "257                 4  799394 14 802393 17 805392 19 808391 34 811389...   \n",
       "258                 4  994719 76 997717 79 1000711 103 1003709 110 10...   \n",
       "259                 4  2057037 10 2060034 13 2063031 17 2066027 21 20...   \n",
       "260                 4  165901 31 168900 33 171891 44 174890 47 177888...   \n",
       "261                 4  529710 25 532708 28 535700 40 538699 43 541698...   \n",
       "262                 4  3707337 1 3710337 2 3713336 4 3716336 6 371933...   \n",
       "263                 4  2170394 3 2173394 6 2176394 7 2179395 7 218239...   \n",
       "264                 4  2989254 26 2992254 28 2995251 35 2998246 45 30...   \n",
       "265                 4  679462 5 682457 13 685448 25 685504 27 688447 ...   \n",
       "266                 4  736706 12 739698 33 742691 52 745689 67 748686...   \n",
       "267                 4  3312310 10 3315310 11 3318301 25 3321299 27 33...   \n",
       "268                 4  793679 20 796675 32 799670 74 802662 95 805654...   \n",
       "269                 4  1430055 19 1430115 36 1433053 21 1433114 38 14...   \n",
       "270                 4  3102247 12 3105246 14 3108246 19 3111245 20 31...   \n",
       "271                 4  934450 1 937448 3 940447 3 943445 5 946444 5 9...   \n",
       "272                 4  1980656 1 1980673 27 1981666 48 1983655 1 1983...   \n",
       "273                 4  4173254 1 4176253 2 4179251 3 4182250 4 418524...   \n",
       "274                 4  1996630 8 1999626 14 2002624 16 2005622 19 200...   \n",
       "275                 4  2184669 23 2187667 27 2190665 31 2193661 37 21...   \n",
       "276                 4  5515207 20 5518204 29 5521202 35 5524202 36 55...   \n",
       "277                 4  1779826 5 1782499 8 1785172 11 1787845 14 1790...   \n",
       "278                 4  3969980 35 3970027 28 3972971 88 3975966 97 39...   \n",
       "279                 4  1611763 11 1614753 29 1617750 35 1620746 43 16...   \n",
       "280                 4  4030400 28 4033466 34 4036526 48 4039594 54 40...   \n",
       "\n",
       "      age     sex  fold  \n",
       "0    37.0    Male     3  \n",
       "1    82.0    Male     2  \n",
       "2    78.0    Male     0  \n",
       "3    21.0  Female     3  \n",
       "4    68.0  Female     0  \n",
       "5    83.0    Male     1  \n",
       "6    57.0    Male     1  \n",
       "7    50.0  Female     3  \n",
       "8    79.0  Female     0  \n",
       "9    60.0    Male     1  \n",
       "10   60.0    Male     2  \n",
       "11   74.0  Female     3  \n",
       "12   21.0  Female     3  \n",
       "13   21.0  Female     1  \n",
       "14   41.0  Female     1  \n",
       "15   73.0    Male     1  \n",
       "16   43.0  Female     1  \n",
       "17   74.0  Female     1  \n",
       "18   60.0    Male     0  \n",
       "19   79.0  Female     2  \n",
       "20   57.0    Male     1  \n",
       "21   83.0    Male     0  \n",
       "22   59.0    Male     3  \n",
       "23   55.0    Male     3  \n",
       "24   61.0    Male     3  \n",
       "25   37.0    Male     2  \n",
       "26   78.0    Male     0  \n",
       "27   74.0  Female     1  \n",
       "28   84.0  Female     3  \n",
       "29   21.0    Male     0  \n",
       "..    ...     ...   ...  \n",
       "251  59.0    Male     1  \n",
       "252  59.0    Male     3  \n",
       "253  43.0  Female     3  \n",
       "254  55.0    Male     1  \n",
       "255  60.0    Male     0  \n",
       "256  68.0  Female     2  \n",
       "257  76.0    Male     3  \n",
       "258  57.0    Male     3  \n",
       "259  21.0    Male     2  \n",
       "260  79.0  Female     2  \n",
       "261  37.0    Male     0  \n",
       "262  78.0    Male     2  \n",
       "263  49.0  Female     2  \n",
       "264  57.0    Male     0  \n",
       "265  83.0    Male     1  \n",
       "266  65.0  Female     1  \n",
       "267  48.0    Male     0  \n",
       "268  84.0    Male     1  \n",
       "269  61.0    Male     1  \n",
       "270  57.0    Male     1  \n",
       "271  57.0    Male     1  \n",
       "272  55.0    Male     2  \n",
       "273  55.0    Male     0  \n",
       "274  49.0  Female     0  \n",
       "275  57.0    Male     1  \n",
       "276  28.0    Male     0  \n",
       "277  57.0  Female     3  \n",
       "278  61.0    Male     2  \n",
       "279  61.0    Male     1  \n",
       "280  28.0    Male     1  \n",
       "\n",
       "[281 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"training\"><center>Training</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf fold-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf fold-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf fold-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.00e-5   00000997   28.49 | 0.753  0.091  0.0000  0.000   | 0.122  0.128   | 677.3351473808289"
     ]
    }
   ],
   "source": [
    "log.write('** start training here! **\\n')\n",
    "log.write('   batch_size = %d \\n'%(batch_size))\n",
    "log.write('                     |-------------- VALID---------|---- TRAIN/BATCH ----------------\\n')\n",
    "log.write('rate     iter  epoch | dice   loss   tp     tn     | loss           | time           \\n')\n",
    "log.write('-------------------------------------------------------------------------------------\\n')\n",
    "\n",
    "valid_loss = np.zeros(4,np.float32)\n",
    "train_loss = np.zeros(2,np.float32)\n",
    "batch_loss = np.zeros_like(train_loss)\n",
    "sum_train_loss = np.zeros_like(train_loss)\n",
    "sum_train = 0\n",
    "\n",
    "start_timer = time.time()\n",
    "iteration = start_iteration\n",
    "epoch = start_epoch\n",
    "rate = 0\n",
    "\n",
    "while iteration < num_iteration:\n",
    "    for t, batch in enumerate(train_loader):\n",
    "\n",
    "        if iteration%iter_save==0:\n",
    "            if iteration != start_iteration:\n",
    "                torch.save({\n",
    "                    'state_dict': net.state_dict(),\n",
    "                    'iteration': iteration,\n",
    "                    'epoch': epoch,\n",
    "                }, out_dir + '/checkpoint/%08d.model.pth' %  (iteration))\n",
    "                pass\n",
    "\n",
    "\n",
    "        if (iteration%iter_valid==0):\n",
    "            valid_loss = validate(net, valid_loader)\n",
    "            pass\n",
    "\n",
    "\n",
    "        if (iteration%iter_log==0) or (iteration%iter_valid==0):\n",
    "            print('\\r', end='', flush=True)\n",
    "            log.write(message(mode='log') + '\\n')\n",
    "\n",
    "\n",
    "        # learning rate schduler ------------\n",
    "        rate = get_learning_rate(optimizer)\n",
    "\n",
    "        # one iteration update  -------------\n",
    "        batch_size = len(batch['index'])\n",
    "        batch['image'] = batch['image'].half().cuda()\n",
    "        batch['mask' ] = batch['mask' ].half().cuda()\n",
    "        batch['organ'] = batch['organ'].cuda()\n",
    "\n",
    "\n",
    "        net.train()\n",
    "        net.output_type = ['loss']\n",
    "        if 1:\n",
    "            with amp.autocast(enabled = is_amp):\n",
    "                output = net(batch)\n",
    "                loss0  = output['bce_loss'].mean()\n",
    "                loss1  = output['aux2_loss'].mean()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss0+0.2*loss1).backward()\n",
    "\n",
    "            scaler.unscale_(optimizer)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "\n",
    "        # print statistics  --------\n",
    "        batch_loss[:2] = [loss0.item(),loss1.item()]\n",
    "        sum_train_loss += batch_loss\n",
    "        sum_train += 1\n",
    "        if t % 100 == 0:\n",
    "            train_loss = sum_train_loss / (sum_train + 1e-12)\n",
    "            sum_train_loss[...] = 0\n",
    "            sum_train = 0\n",
    "\n",
    "        print('\\r', end='', flush=True)\n",
    "        print(message(mode='log'), end='', flush=True)\n",
    "        epoch += 1 / len(train_loader)\n",
    "        iteration += 1\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    log.flush()\n",
    "    clear_output()\n",
    "    \n",
    "log.write('\\n')\n",
    "log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.10 :: Anaconda, Inc.\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list > ed_config.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug  5 11:29:43 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.152.00   Driver Version: 418.152.00   CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-DGXS...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    40W / 300W |     57MiB / 32478MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS...  On   | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    54W / 300W |   8184MiB / 32478MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS...  On   | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    52W / 300W |   6319MiB / 32478MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS...  On   | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    51W / 300W |   6285MiB / 32478MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
