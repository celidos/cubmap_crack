{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height:200px;width:100%;margin: 0;\">\n",
    "    <img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/34547/logos/header.png?t=2022-02-15-22-37-27\" style=\"width:100%;\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"credits\"><center>Credits</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the reverse engineering of the [hengck23 discussion](https://www.kaggle.com/code/hengck23/lb-0-75-variable-size-swin-transformer-v1-and-v2).<br>\n",
    "Please upvote both discussion/notebooks if you are planning to use Swin Transformers or any part of the code.\n",
    "\n",
    "**hengck23 owner Disclaimer**\n",
    "\n",
    "[1] the code is taken from a larger project and is by no means complete. It will has missing import modules, etc. But these are trival functions that you can ignore or fill in yourself.\n",
    "\n",
    "[2] you are free to use, modify the code for your own notebook or submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"imports\"><center>Imports</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.cuda.amp as amp\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import RandomSampler \n",
    "from torch.utils.data import SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional import dice_score\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "is_amp = True\n",
    "import logging\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import numpy as np\n",
    "from itertools import repeat\n",
    "import collections.abc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import tifffile\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.2+cu102'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"paths\"><center>Paths</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPATIAL_SIZE = 1500\n",
    "# for fname in tqdm(glob('./../data/train_images/*.tiff')):\n",
    "#     image = tifffile.imread(fname)\n",
    "#     image = cv.resize(image, (SPATIAL_SIZE, SPATIAL_SIZE))\n",
    "#     image = image[:, :, ::-1]\n",
    "#     newfname = './../data/train_images_{}/'.format(SPATIAL_SIZE) +\\\n",
    "#         os.path.splitext(os.path.basename(fname))[0] + '.png'\n",
    "#     cv.imwrite(newfname, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fname in tqdm(glob('./../data/train_masks/*.npy')):\n",
    "#     mask = np.load(fname)\n",
    "#     mask = cv.resize(mask, (SPATIAL_SIZE, SPATIAL_SIZE))\n",
    "#     newfname = './../data/train_masks_{}/'.format(SPATIAL_SIZE) +\\\n",
    "#         os.path.splitext(os.path.basename(fname))[0] + '.npy'\n",
    "#     np.save(newfname, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_dir = '.'\n",
    "root_dir = '.'\n",
    "\n",
    "DATA_PATH = Path('/home/liza/temp/data/hubmap')\n",
    "IMAGES = DATA_PATH / 'train_images'\n",
    "MASKS = DATA_PATH / 'train_masks'\n",
    "LABELS = DATA_PATH / 'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = np.load(MASKS / '10044.npz')['arr_0']\n",
    "plt.imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.min(), mask.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"additionals\"><center>Additionals</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# OK, BUT NOT ALL PRESENTED\n",
    "\n",
    "def image_to_tensor(image, mode='bgr'): # image mode\n",
    "    if mode=='bgr':\n",
    "        image = image[:,:,::-1]\n",
    "    x = image\n",
    "    x = x.transpose(2,0,1)\n",
    "    x = np.ascontiguousarray(x)\n",
    "    x = torch.tensor(x, dtype=torch.float)\n",
    "    return x\n",
    "\n",
    "\n",
    "def mask_to_tensor(mask):\n",
    "    x = mask\n",
    "    x = torch.tensor(x, dtype=torch.float)\n",
    "    return x\n",
    "\n",
    "\n",
    "tensor_list = ['mask', 'image', 'organ']\n",
    "\n",
    "def null_collate(batch):\n",
    "    d = {}\n",
    "    key = batch[0].keys()\n",
    "    for k in key:\n",
    "        v = [b[k] for b in batch]\n",
    "        if k in tensor_list:\n",
    "            v = torch.stack(v)\n",
    "        d[k] = v\n",
    "\n",
    "    d['mask'] = d['mask'].unsqueeze(1)\n",
    "    d['organ'] = d['organ'].reshape(-1)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "def _ntuple(n):\n",
    "    def parse(x):\n",
    "        if isinstance(x, collections.abc.Iterable):\n",
    "            return x\n",
    "        return tuple(repeat(x, n))\n",
    "    return parse\n",
    "\n",
    "\n",
    "to_2tuple = _ntuple(2)\n",
    "    \n",
    "# ok\n",
    "def message(mode='print'):\n",
    "    asterisk = ' '\n",
    "    if mode==('print'):\n",
    "        loss = batch_loss\n",
    "    if mode==('log'):\n",
    "        loss = train_loss\n",
    "        if (iteration % iter_save == 0): asterisk = '*'\n",
    "\n",
    "    text = \\\n",
    "        ('%0.2e   %08d%s %6.2f | '%(rate, iteration, asterisk, epoch,)).replace('e-0','e-').replace('e+0','e+') + \\\n",
    "        '%4.3f  %4.3f  %4.4f  %4.3f   | '%(*valid_loss,) + \\\n",
    "        '%4.3f  %4.3f   | '%(*loss,) + \\\n",
    "        '%s' % ((time.time() - start_timer))\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"randoms\"><center>Random choice</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok\n",
    "\n",
    "def valid_augment5(image, mask, organ):\n",
    "    #image, mask  = do_crop(image, mask, image_size, xy=(None,None))\n",
    "    return image, mask\n",
    "\n",
    "def train_augment5b(image, mask, organ):\n",
    "    image, mask = do_random_flip(image, mask)\n",
    "    image, mask = do_random_rot90(image, mask)\n",
    "\n",
    "    for fn in np.random.choice([\n",
    "        lambda image, mask: (image, mask),\n",
    "        lambda image, mask: do_random_noise(image, mask, mag=0.1),\n",
    "        lambda image, mask: do_random_contast(image, mask, mag=0.40),\n",
    "        lambda image, mask: do_random_hsv(image, mask, mag=[0.40, 0.40, 0])\n",
    "    ], 2): image, mask = fn(image, mask)\n",
    "\n",
    "    for fn in np.random.choice([\n",
    "        lambda image, mask: (image, mask),\n",
    "        lambda image, mask: do_random_rotate_scale(image, mask, angle=45, scale=[0.50, 2.0]),\n",
    "    ], 1): image, mask = fn(image, mask)\n",
    "\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"augmentations\"><center>Augmentations</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# TODO CUTOUT\n",
    "# NOT EVERY AUGMENTATION IS PRESENTED FROM THE ORIGINAL CODE\n",
    "# other is ok\n",
    "\n",
    "def do_random_flip(image, mask):\n",
    "    if np.random.rand()>0.5:\n",
    "        image = cv2.flip(image,0)\n",
    "        mask = cv2.flip(mask,0)\n",
    "    if np.random.rand()>0.5:\n",
    "        image = cv2.flip(image,1)\n",
    "        mask = cv2.flip(mask,1)\n",
    "    if np.random.rand()>0.5:\n",
    "        image = image.transpose(1,0,2)\n",
    "        mask = mask.transpose(1,0)\n",
    "    \n",
    "    image = np.ascontiguousarray(image)\n",
    "    mask = np.ascontiguousarray(mask)\n",
    "    return image, mask\n",
    "\n",
    "def do_random_rot90(image, mask):\n",
    "    r = np.random.choice([\n",
    "        0,\n",
    "        cv2.ROTATE_90_CLOCKWISE,\n",
    "        cv2.ROTATE_90_COUNTERCLOCKWISE,\n",
    "        cv2.ROTATE_180,\n",
    "    ])\n",
    "    if r==0:\n",
    "        return image, mask\n",
    "    else:\n",
    "        image = cv2.rotate(image, r)\n",
    "        mask = cv2.rotate(mask, r)\n",
    "        return image, mask\n",
    "    \n",
    "def do_random_contast(image, mask, mag=0.3):\n",
    "    alpha = 1 + random.uniform(-1,1)*mag\n",
    "    image = image * alpha\n",
    "    image = np.clip(image,0,1)\n",
    "    return image, mask\n",
    "\n",
    "def do_random_hsv(image, mask, mag=[0.15,0.25,0.25]):\n",
    "    image = (image*255).astype(np.uint8)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    h = hsv[:, :, 0].astype(np.float32)  # hue\n",
    "    s = hsv[:, :, 1].astype(np.float32)  # saturation\n",
    "    v = hsv[:, :, 2].astype(np.float32)  # value\n",
    "    h = (h*(1 + random.uniform(-1,1)*mag[0]))%180\n",
    "    s =  s*(1 + random.uniform(-1,1)*mag[1])\n",
    "    v =  v*(1 + random.uniform(-1,1)*mag[2])\n",
    "\n",
    "    hsv[:, :, 0] = np.clip(h,0,180).astype(np.uint8)\n",
    "    hsv[:, :, 1] = np.clip(s,0,255).astype(np.uint8)\n",
    "    hsv[:, :, 2] = np.clip(v,0,255).astype(np.uint8)\n",
    "    image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    image = image.astype(np.float32)/255\n",
    "    return image, mask\n",
    "\n",
    "def do_random_noise(image, mask, mag=0.1):\n",
    "    height, width = image.shape[:2]\n",
    "    noise = np.random.uniform(-1,1, (height, width,1))*mag\n",
    "    image = image + noise\n",
    "    image = np.clip(image,0,1)\n",
    "    return image, mask\n",
    "\n",
    "def do_random_rotate_scale(image, mask, angle=30, scale=[0.8,1.2] ):\n",
    "    angle = np.random.uniform(-angle, angle)\n",
    "    scale = np.random.uniform(*scale) if scale is not None else 1\n",
    "    \n",
    "    height, width = image.shape[:2]\n",
    "    center = (height // 2, width // 2)\n",
    "    \n",
    "    transform = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    image = cv2.warpAffine( image, transform, (width, height), flags=cv2.INTER_LINEAR,\n",
    "                            borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))\n",
    "    mask  = cv2.warpAffine( mask, transform, (width, height), flags=cv2.INTER_LINEAR,\n",
    "                            borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "    return image, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"dataset\"><center>Dataset</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTOK\n",
    "# Recheck input\n",
    "\n",
    "image_size = 768\n",
    "\n",
    "class HubmapDataset(Dataset):\n",
    "    def __init__(self, df, augment=None):\n",
    "\n",
    "        self.df = df\n",
    "        self.augment = augment\n",
    "        self.length = len(self.df)\n",
    "        self.organ_to_label = {'kidney' : 0,\n",
    "                               'prostate' : 1,\n",
    "                               'largeintestine' : 2,\n",
    "                               'spleen' : 3,\n",
    "                               'lung' : 4}\n",
    "\n",
    "    def __str__(self):\n",
    "        string = ''\n",
    "        string += '\\tlen = %d\\n' % len(self)\n",
    "\n",
    "        d = self.df.organ.value_counts().to_dict()\n",
    "        for k in ['kidney', 'prostate', 'largeintestine', 'spleen', 'lung']:\n",
    "            string +=  '%24s %3d (%0.3f) \\n'%(k,d.get(k,0),d.get(k,0)/len(self.df))\n",
    "        return string\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        d = self.df.iloc[index]\n",
    "        id = d['id']\n",
    "        organ = self.organ_to_label[d.organ]\n",
    "\n",
    "        fname_img = os.path.join(IMAGES, f'{id}.npz')\n",
    "        fname_msk = os.path.join(MASKS, f'{id}.npz')\n",
    "        \n",
    "        # image = cv2.cvtColor(cv2.imread(fname_img), cv2.COLOR_BGR2RGB)\n",
    "        image = np.load(fname_img)['arr_0']\n",
    "        \n",
    "        # mask = cv2.imread(os.path.join(MASKS,fname),cv2.IMREAD_GRAYSCALE)\n",
    "        # mask = np.load(fname_msk, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = np.load(fname_msk)['arr_0']\n",
    "\n",
    "        \n",
    "        image = image.astype(np.float32)/255\n",
    "        mask  = mask.astype(np.float32) #/255\n",
    "\n",
    "        # s = d.pixel_size/0.4 * (image_size/3000)\n",
    "        image = cv2.resize(image, dsize=(image_size,image_size), interpolation=cv2.INTER_LINEAR)\n",
    "        mask  = cv2.resize(mask, dsize=(image_size,image_size), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        if self.augment is not None:\n",
    "            image, mask = self.augment(image, mask, organ)\n",
    "\n",
    "        r ={}\n",
    "        r['index']= index\n",
    "        r['id'] = id\n",
    "        r['organ'] = torch.tensor([organ], dtype=torch.long)\n",
    "        r['image'] = image_to_tensor(image, mode='rgb')\n",
    "        r['mask' ] = mask_to_tensor(mask>0.5)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"patching\"><center>NETWORK</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "from swintransformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok\n",
    "\n",
    "cfg = dict(\n",
    "\n",
    "        #configs/_base_/models/upernet_swin.py\n",
    "        basic = dict(\n",
    "            swin=dict(\n",
    "                embed_dim=96,\n",
    "                depths=[2, 2, 6, 2],\n",
    "                num_heads=[3, 6, 12, 24],\n",
    "                window_size=7,\n",
    "                mlp_ratio=4.,\n",
    "                qkv_bias=True,\n",
    "                qk_scale=None,\n",
    "                drop_rate=0.,\n",
    "                attn_drop_rate=0.,\n",
    "                drop_path_rate=0.3,\n",
    "                ape=False,\n",
    "                patch_norm=True,\n",
    "                out_indices=(0, 1, 2, 3),\n",
    "                use_checkpoint=False\n",
    "            ),\n",
    "\n",
    "        ),\n",
    "\n",
    "        #configs/swin/upernet_swin_tiny_patch4_window7_512x512_160k_ade20k.py\n",
    "        swin_tiny_patch4_window7_224=dict(\n",
    "            checkpoint = pretrain_dir+'/swin_tiny_patch4_window7_224_22k.pth',\n",
    "\n",
    "            swin = dict(\n",
    "                embed_dim=96,\n",
    "                depths=[2, 2, 6, 2],\n",
    "                num_heads=[3, 6, 12, 24],\n",
    "                window_size=7,\n",
    "                ape=False,\n",
    "                drop_path_rate=0.3,\n",
    "                patch_norm=True,\n",
    "                use_checkpoint=False,\n",
    "            ),\n",
    "            upernet=dict(\n",
    "                in_channels=[96, 192, 384, 768],\n",
    "            ),\n",
    "        ),\n",
    "\n",
    "        #/configs/swin/upernet_swin_small_patch4_window7_512x512_160k_ade20k.py\n",
    "        swin_small_patch4_window7_224_22k=dict(\n",
    "            checkpoint = pretrain_dir+'/swin_small_patch4_window7_224_22k.pth',\n",
    "\n",
    "            swin = dict(\n",
    "                embed_dim=96,\n",
    "                depths=[2, 2, 18, 2],\n",
    "                num_heads=[3, 6, 12, 24],\n",
    "                window_size=7,\n",
    "                ape=False,\n",
    "                drop_path_rate=0.3,\n",
    "                patch_norm=True,\n",
    "                use_checkpoint=False\n",
    "            ),\n",
    "            upernet=dict(\n",
    "                in_channels=[96, 192, 384, 768],\n",
    "            ),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"folds\"><center>Folds</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok\n",
    "\n",
    "def make_fold(fold=0):\n",
    "    # df = pd.read_csv(root_dir + '/../data/train.csv')\n",
    "    df = pd.read_csv(LABELS)\n",
    "\n",
    "    num_fold = 5\n",
    "    skf = KFold(n_splits=num_fold, shuffle=True, random_state=42)\n",
    "\n",
    "    df.loc[:,'fold']=-1\n",
    "    for f,(t_idx, v_idx) in enumerate(skf.split(X=df['id'], y=df['organ'])):\n",
    "        df.iloc[v_idx,-1]=f\n",
    "\n",
    "    #check\n",
    "    if 0:\n",
    "        for f in range(num_fold):\n",
    "            train_df=df[df.fold!=f].reset_index(drop=True)\n",
    "            valid_df=df[df.fold==f].reset_index(drop=True)\n",
    "\n",
    "            print('fold %d'%f)\n",
    "            t = train_df.organ.value_counts().to_dict()\n",
    "            v = valid_df.organ.value_counts().to_dict()\n",
    "            for k in ['kidney', 'prostate', 'largeintestine', 'spleen', 'lung']:\n",
    "                print('%32s %3d (%0.3f)  %3d (%0.3f)'%(k,t.get(k,0),t.get(k,0)/len(train_df),v.get(k,0),v.get(k,0)/len(valid_df)))\n",
    "\n",
    "            print('')\n",
    "            zz=0\n",
    "\n",
    "    train_df=df[df.fold!=fold].reset_index(drop=True)\n",
    "    valid_df=df[df.fold==fold].reset_index(drop=True)\n",
    "    return train_df,valid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"dice_score\"><center>Competition Metric</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dice_score(probability, mask):\n",
    "    N = len(probability)\n",
    "    p = probability.reshape(N,-1)\n",
    "    t = mask.reshape(N,-1)\n",
    "\n",
    "    p = p>0.5\n",
    "    t = t>0.5\n",
    "    uion = p.sum(-1) + t.sum(-1)\n",
    "    overlap = (p*t).sum(-1)\n",
    "    dice = 2*overlap/(uion+0.0001)\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"validation\"><center>Validation</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok\n",
    "\n",
    "def validate(net, valid_loader):\n",
    "\n",
    "    valid_num = 0\n",
    "    valid_probability = []\n",
    "    valid_mask = []\n",
    "    valid_loss = 0\n",
    "\n",
    "    net = net.eval()\n",
    "    start_timer = time.time()\n",
    "    for t, batch in enumerate(valid_loader):\n",
    "\n",
    "        net.output_type = ['loss', 'inference']\n",
    "        with torch.no_grad():\n",
    "            with amp.autocast(enabled = is_amp):\n",
    "\n",
    "                batch_size = len(batch['index'])\n",
    "                batch['image'] = batch['image'].cuda()\n",
    "                batch['mask' ] = batch['mask' ].cuda()\n",
    "                batch['organ'] = batch['organ'].cuda()\n",
    "\n",
    "                output = net(batch)\n",
    "                loss0  = output['bce_loss'].mean()\n",
    "\n",
    "        valid_probability.append(output['probability'].data.cpu().numpy())\n",
    "        valid_mask.append(batch['mask'].data.cpu().numpy())\n",
    "        valid_num += batch_size\n",
    "        valid_loss += batch_size*loss0.item()\n",
    "\n",
    "        #debug\n",
    "        if 0 :\n",
    "            pass\n",
    "            organ = batch['organ'].data.cpu().numpy()\n",
    "            image = batch['image']\n",
    "            mask  = batch['mask']\n",
    "            probability  = output['probability']\n",
    "\n",
    "            for b in range(batch_size):\n",
    "                m = tensor_to_image(image[b])\n",
    "                t = tensor_to_mask(mask[b,0])\n",
    "                p = tensor_to_mask(probability[b,0])\n",
    "                overlay = result_to_overlay(m, t, p )\n",
    "\n",
    "                text = label_to_organ[organ[b]]\n",
    "                draw_shadow_text(overlay,text,(5,15),0.7,(1,1,1),1)\n",
    "\n",
    "                image_show_norm('overlay',overlay,min=0,max=1,resize=1)\n",
    "                cv2.waitKey(0)\n",
    "\n",
    "        print('\\r %8d / %d  %s'%(valid_num, len(valid_loader.dataset),(time.time() - start_timer)),end='',flush=True)\n",
    "\n",
    "    assert(valid_num == len(valid_loader.dataset))\n",
    "\n",
    "    probability = np.concatenate(valid_probability)\n",
    "    mask = np.concatenate(valid_mask)\n",
    "\n",
    "    loss = valid_loss/valid_num\n",
    "\n",
    "    dice = compute_dice_score(probability, mask)\n",
    "    dice = dice.mean()\n",
    "    \n",
    "    return [dice, loss,  0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"init\"><center>Initialization</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learning_rate(optimizer):\n",
    "    return optimizer.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./swin_tiny_patch4_window7_224_22k.pth ...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './swin_tiny_patch4_window7_224_22k.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     start_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     71\u001b[0m     start_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 72\u001b[0m     \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_pretrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m log\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124minitial_checkpoint = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m initial_checkpoint)\n\u001b[1;32m     76\u001b[0m log\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/temp/cubmap_crack/swin-transformer-liza/swintransformer.py:694\u001b[0m, in \u001b[0;36mNet.load_pretrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    692\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39march][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39mcheckpoint)\n\u001b[0;32m--> 694\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    696\u001b[0m     skip \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelative_coords_table\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelative_position_index\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/hubmap/lib/python3.9/site-packages/torch/serialization.py:594\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    592\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    596\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    599\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/envs/hubmap/lib/python3.9/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniconda3/envs/hubmap/lib/python3.9/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './swin_tiny_patch4_window7_224_22k.pth'"
     ]
    }
   ],
   "source": [
    "# ok\n",
    "\n",
    "fold = FOLD\n",
    "\n",
    "out_dir = root_dir + '/fold-%d' % (fold)\n",
    "initial_checkpoint = None\n",
    "\n",
    "start_lr   = 5e-5 #0.0001\n",
    "batch_size = 8 #32 #32\n",
    "\n",
    "\n",
    "## setup  ----------------------------------------\n",
    "for f in ['checkpoint','train','valid','backup'] : os.makedirs(out_dir +'/'+f, exist_ok=True)\n",
    "\n",
    "    \n",
    "log = open(out_dir+'/log.train.txt',mode='a')\n",
    "log.write('\\n--- [START %s] %s\\n\\n' % ('Swin', '-' * 64))\n",
    "log.write('\\n')\n",
    "\n",
    "\n",
    "## dataset ----------------------------------------\n",
    "log.write('** dataset setting **\\n')\n",
    "\n",
    "train_df, valid_df = make_fold(fold)\n",
    "\n",
    "train_dataset = HubmapDataset(train_df, train_augment5b)\n",
    "valid_dataset = HubmapDataset(valid_df, valid_augment5)\n",
    "\n",
    "train_loader  = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler = RandomSampler(train_dataset),\n",
    "    batch_size  = batch_size,\n",
    "    drop_last   = True,\n",
    "    num_workers = 8,\n",
    "    pin_memory  = False,\n",
    "    worker_init_fn = lambda id: np.random.seed(torch.initial_seed() // 2 ** 32 + id),\n",
    "    collate_fn = null_collate,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    sampler = SequentialSampler(valid_dataset),\n",
    "    batch_size  = 8,\n",
    "    drop_last   = False,\n",
    "    num_workers = 4,\n",
    "    pin_memory  = False,\n",
    "    collate_fn = null_collate,\n",
    ")\n",
    "\n",
    "\n",
    "log.write('fold = %s\\n'%str(fold))\n",
    "log.write('train_dataset : \\n%s\\n'%(train_dataset))\n",
    "log.write('valid_dataset : \\n%s\\n'%(valid_dataset))\n",
    "log.write('\\n')\n",
    "\n",
    "\n",
    "## net ----------------------------------------\n",
    "log.write('** net setting **\\n')\n",
    "\n",
    "scaler = amp.GradScaler(enabled = is_amp)\n",
    "net = Net(cfg).cuda()\n",
    "\n",
    "if initial_checkpoint is not None:\n",
    "    f = torch.load(initial_checkpoint, map_location=lambda storage, loc: storage)\n",
    "    start_iteration = f['iteration']\n",
    "    start_epoch = f['epoch']\n",
    "    state_dict  = f['state_dict']\n",
    "    net.load_state_dict(state_dict,strict=False)  #True\n",
    "else:\n",
    "    start_iteration = 0\n",
    "    start_epoch = 0\n",
    "    net.load_pretrain()\n",
    "\n",
    "\n",
    "log.write('\\tinitial_checkpoint = %s\\n' % initial_checkpoint)\n",
    "log.write('\\n')\n",
    "\n",
    "\n",
    "## optimiser ----------------------------------\n",
    "if 0: ##freeze\n",
    "    for p in net.stem.parameters():   p.requires_grad = False\n",
    "    pass\n",
    "\n",
    "def freeze_bn(net):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            m.eval()\n",
    "            m.weight.requires_grad = False\n",
    "            m.bias.requires_grad = False\n",
    "            \n",
    "#freeze_bn(net)\n",
    "\n",
    "#-----------------------------------------------\n",
    "\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, net.parameters()),\n",
    "                              lr=start_lr)\n",
    "#optimizer = Lookahead(RAdam(filter(lambda p: p.requires_grad, net.parameters()),lr=start_lr), alpha=0.5, k=5)\n",
    "    \n",
    "log.write('optimizer\\n  %s\\n'%(optimizer))\n",
    "log.write('\\n')\n",
    "\n",
    "num_iteration = 1000*len(train_loader)\n",
    "iter_log   = len(train_loader)*3 #479\n",
    "iter_valid = iter_log\n",
    "iter_save  = iter_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:#c3448b; background:#efe9e9; border:1px dashed #efe50b;\" role=\"tab\" aria-controls=\"training\"><center>Training</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok\n",
    "\n",
    "log.write('** start training here! **\\n')\n",
    "log.write('   batch_size = %d \\n'%(batch_size))\n",
    "log.write('                     |-------------- VALID---------|---- TRAIN/BATCH ----------------\\n')\n",
    "log.write('rate     iter  epoch | dice   loss   tp     tn     | loss           | time           \\n')\n",
    "log.write('-------------------------------------------------------------------------------------\\n')\n",
    "\n",
    "valid_loss = np.zeros(4,np.float32)\n",
    "train_loss = np.zeros(2,np.float32)\n",
    "batch_loss = np.zeros_like(train_loss)\n",
    "sum_train_loss = np.zeros_like(train_loss)\n",
    "sum_train = 0\n",
    "\n",
    "start_timer = time.time()\n",
    "iteration = start_iteration\n",
    "epoch = start_epoch\n",
    "rate = 0\n",
    "\n",
    "while iteration < num_iteration:\n",
    "    for t, batch in enumerate(train_loader):\n",
    "\n",
    "        if iteration%iter_save==0:\n",
    "            if iteration != start_iteration:\n",
    "                torch.save({\n",
    "                    'state_dict': net.state_dict(),\n",
    "                    'iteration': iteration,\n",
    "                    'epoch': epoch,\n",
    "                }, out_dir + '/checkpoint/%08d.model.pth' %  (iteration))\n",
    "                pass\n",
    "\n",
    "\n",
    "        if (iteration%iter_valid==0):\n",
    "            valid_loss = validate(net, valid_loader)\n",
    "            pass\n",
    "\n",
    "\n",
    "        if (iteration%iter_log==0) or (iteration%iter_valid==0):\n",
    "            print('\\r', end='', flush=True)\n",
    "            log.write(message(mode='log') + '\\n')\n",
    "\n",
    "\n",
    "        # learning rate schduler ------------\n",
    "        rate = get_learning_rate(optimizer)\n",
    "\n",
    "        # one iteration update  -------------\n",
    "        batch_size = len(batch['index'])\n",
    "        batch['image'] = batch['image'].half().cuda()\n",
    "        batch['mask' ] = batch['mask' ].half().cuda()\n",
    "        batch['organ'] = batch['organ'].cuda()\n",
    "\n",
    "\n",
    "        net.train()\n",
    "        net.output_type = ['loss']\n",
    "        if 1:\n",
    "            with amp.autocast(enabled = is_amp):\n",
    "                output = net(batch)\n",
    "                loss0  = output['bce_loss'].mean()\n",
    "                loss1  = output['aux2_loss'].mean()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss0+0.2*loss1).backward()\n",
    "\n",
    "            scaler.unscale_(optimizer)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "\n",
    "        # print statistics  --------\n",
    "        batch_loss[:2] = [loss0.item(),loss1.item()]\n",
    "        sum_train_loss += batch_loss\n",
    "        sum_train += 1\n",
    "        if t % 100 == 0:\n",
    "            train_loss = sum_train_loss / (sum_train + 1e-12)\n",
    "            sum_train_loss[...] = 0\n",
    "            sum_train = 0\n",
    "\n",
    "        print('\\r', end='', flush=True)\n",
    "        print(message(mode='log'), end='', flush=True)\n",
    "        epoch += 1 / len(train_loader)\n",
    "        iteration += 1\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    log.flush()\n",
    "#     clear_output()\n",
    "    \n",
    "log.write('\\n')\n",
    "log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
